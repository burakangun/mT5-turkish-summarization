{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"batubayk/TR-News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract    Şarkıcı Tuğba Özerk, annesine canlı yayında yö...\n",
      "author                                                   None\n",
      "content     Tuğba Özerk, “Duymayan Kalmasın” programında, ...\n",
      "date                                       13.01.2017 - 12:38\n",
      "source                                              haberturk\n",
      "tags                                                       []\n",
      "title       Tuğba Özerk'ten Deniz Akkaya’ya 100 bin TL’lik...\n",
      "topic                                                  Fiskos\n",
      "url         https://www.haberturk.com/magazin/fiskos/haber...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_ds = ds['train']\n",
    "\n",
    "\n",
    "# DataFrame'e çevirme\n",
    "dataset_new = pd.DataFrame(train_ds)\n",
    "\n",
    "# İlk satıra erişim (iloc ile)\n",
    "print(dataset_new.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Burak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Burak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Burak\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import pytorch_lightning as pl\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('omw-1.4')\n",
    "import os\n",
    "import string\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2026"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_new.head()\n",
    "len(dataset_new.iloc[8].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a47d86bb074e4ea07adacd7f99d840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409d2aa3e85f473faed9348abc4e7f08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5e9464dae641c88add101ea27a8bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1fe96493494e2c912a047b211d0fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d054385dd51d45f6925d07937e7d0773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-large\", return_dict=True)\n",
    "TOKENIZER = T5Tokenizer.from_pretrained(\"t5-large\")\n",
    "BATCH_SIZE = 1\n",
    "TEXT_LEN = 2048\n",
    "HEADLINE_LEN = 64\n",
    "EPOCHS = 3\n",
    "# GPU kontrolü\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Training on: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummaryDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, text_len, headline_len):\n",
    "        self.dataset_new= dataset_new\n",
    "        self.headlines = self.dataset_new[\"abstract\"]\n",
    "        self.text = self.dataset_new[\"content\"]\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_len = text_len\n",
    "        self.headline_len = headline_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.headlines)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        # T5 transformers performs different tasks by prepending the particular prefix to the input text.\n",
    "        text = \"summarize:\" + str(self.text[idx])                # In order to avoid dtype mismatch, as T5 is text-to-text transformer, the datatype must be string\n",
    "        headline = str(self.headlines[idx])\n",
    "\n",
    "        text_tokenizer = self.tokenizer(text, max_length=self.text_len, padding=\"max_length\",\n",
    "                                                        truncation=True, add_special_tokens=True)\n",
    "        headline_tokenizer = self.tokenizer(headline, max_length=self.headline_len, padding=\"max_length\",\n",
    "                                                        truncation=True, add_special_tokens=True)\n",
    "        return {\n",
    "            \"input_ids\": torch.tensor(text_tokenizer[\"input_ids\"], dtype=torch.long),\n",
    "            \"attention_mask\": torch.tensor(text_tokenizer[\"attention_mask\"], dtype=torch.long),\n",
    "            \"summary_ids\": torch.tensor(headline_tokenizer[\"input_ids\"], dtype=torch.long),\n",
    "            \"summary_mask\": torch.tensor(headline_tokenizer[\"attention_mask\"], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummaryDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                train_df, \n",
    "                val_df,\n",
    "                test_df,\n",
    "                batch_size,\n",
    "                tokenizer,\n",
    "                text_len,\n",
    "                summary_len):\n",
    "        super().__init__()\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.batch_size = batch_size\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_len = text_len\n",
    "        self.summary_len = summary_len\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = NewsSummaryDataset(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.text_len,\n",
    "            self.summary_len)\n",
    "        \n",
    "        self.val_dataset = NewsSummaryDataset(\n",
    "            self.val_df,\n",
    "            self.tokenizer,\n",
    "            self.text_len,\n",
    "            self.summary_len)\n",
    "        \n",
    "        self.test_dataset = NewsSummaryDataset(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.text_len,\n",
    "            self.summary_len\n",
    "        )\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=4)\n",
    "        \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "              self.test_dataset,\n",
    "              batch_size=self.batch_size,\n",
    "              num_workers=4\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(dataset_new, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_summary_module = NewsSummaryDataModule(train_df, val_df, test_df, BATCH_SIZE, TOKENIZER, TEXT_LEN, HEADLINE_LEN)\n",
    "news_summary_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsSummaryModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(NewsSummaryModel, self).__init__()\n",
    "        self.model = MODEL\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask, labels=None, decoder_attention_mask=None):\n",
    "        outputs = self.model(input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels,\n",
    "                        decoder_attention_mask=decoder_attention_mask)\n",
    "        return outputs.loss, outputs.logits\n",
    "  \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"summary_ids\"]\n",
    "        decoder_attention_mask = batch[\"summary_mask\"]\n",
    "\n",
    "        loss, output = self(input_ids, attention_mask, labels, decoder_attention_mask)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"summary_ids\"]\n",
    "        decoder_attention_mask = batch[\"summary_mask\"]\n",
    "\n",
    "        loss, output = self(input_ids, attention_mask, labels, decoder_attention_mask)\n",
    "        return loss\n",
    " \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        loss, output = self(input_ids=input_ids, \n",
    "                      attention_mask=attention_mask)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.model.parameters(), lr=0.0001)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=0,\n",
    "                num_training_steps=EPOCHS*len(dataset_new))\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NewsSummaryModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params | Mode\n",
      "------------------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 737 M  | eval\n",
      "------------------------------------------------------------\n",
      "737 M     Trainable params\n",
      "0         Non-trainable params\n",
      "737 M     Total params\n",
      "2,950.672 Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "1069      Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca883ceaa574205b082f405e908e30b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0]  # GPU 0 ve 1'i kullanmak için\n",
    ")\n",
    "\n",
    "trainer.fit(model, news_summary_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
