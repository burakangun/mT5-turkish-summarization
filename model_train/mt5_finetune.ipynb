{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ekY1xSZaPV6x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import TFMT5ForConditionalGeneration, MT5Tokenizer, DataCollatorForSeq2Seq\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sq8j-TtSJNL",
        "outputId": "4cf63a54-477d-4f69-e8b3-b6f1432e601c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AnCFjnROPV6z"
      },
      "outputs": [],
      "source": [
        "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5pNjX-tPV61",
        "outputId": "4c62c768-5b1a-412e-c70d-27570aafcbca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 138786\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 14610\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 15379\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "\n",
        "# Hugging Face'ten veri setini yÃ¼kleme\n",
        "dataset = load_dataset(\"batubayk/TR-News\")  # Kendi veri setinizin adÄ±nÄ± yazÄ±n\n",
        "\n",
        "# Train ve validation setlerini alÄ±n\n",
        "train_dataset = dataset['train']\n",
        "val_dataset = dataset['validation']\n",
        "test_dataset = dataset['test']\n",
        "# Train dataset'in yarÄ±sÄ±nÄ± alma\n",
        "train_half = train_dataset.select(range(len(train_dataset) // 2))\n",
        "\n",
        "\n",
        "# TÃ¼m veri setlerini bir DatasetDict'e dÃ¶nÃ¼ÅŸtÃ¼rme\n",
        "combined_datasets = DatasetDict({\n",
        "    'train': train_half,       # YarÄ±ya indirgenmiÅŸ train set\n",
        "    'validation': val_dataset, # Validation set\n",
        "    'test': test_dataset       # Test set\n",
        "})\n",
        "\n",
        "# BirleÅŸtirilmiÅŸ veri setini gÃ¶rÃ¼ntÃ¼leme\n",
        "print(combined_datasets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ympBvHoxPV64",
        "outputId": "16ea2cd0-a8b2-4f8c-f4b3-b4b7d9f1de66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 138786\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14610\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 15379\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "def tokenize_sample_data(data):\n",
        "\n",
        "    input_feature = tokenizer(data['content'], truncation=True, max_length=1024)\n",
        "    label = tokenizer(data['abstract'], truncation=True, max_length=128)\n",
        "    return {\n",
        "        \"input_ids\" : input_feature['input_ids'],\n",
        "        \"attention_mask\" : input_feature['attention_mask'],\n",
        "        \"labels\" : label['input_ids'],\n",
        "    }\n",
        "\n",
        "tokenized_ds = combined_datasets.map(\n",
        "    tokenize_sample_data,\n",
        "    remove_columns= ['abstract','author','content','date','source','tags','title','topic','url'],\n",
        "    batched=True,\n",
        "    batch_size= 512\n",
        ")\n",
        "tokenized_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "hQwKEJ42PV65",
        "outputId": "2bc1c13d-2a84-44fc-f1b5-cd570fea74d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nfrom transformers import MT5Tokenizer, MT5ForConditionalGeneration\\n\\n# 1. Tokenizer ve modelin yÃ¼klenmesi\\nmodel_name = \"google/mt5-small\"\\ntokenizer = MT5Tokenizer.from_pretrained(model_name)\\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)\\n\\n# 2. Ã–zetlenmek istenen TÃ¼rkÃ§e metin\\nturkish_text = \"\"\"\\nÄ°klim deÄŸiÅŸikliÄŸi, kÃ¼resel sÄ±caklÄ±klarÄ±n artÄ±ÅŸÄ±yla birlikte ortaya Ã§Ä±kan Ã§evresel, sosyal ve ekonomik sorunlara neden olmaktadÄ±r.\\nÃ–zellikle kuraklÄ±k, sel ve orman yangÄ±nlarÄ± gibi doÄŸal afetlerin sÄ±klÄ±ÄŸÄ± artarken, tarÄ±msal Ã¼retimde de ciddi dÃ¼ÅŸÃ¼ÅŸler yaÅŸanmaktadÄ±r.\\nBu durum, gÄ±da gÃ¼venliÄŸini tehdit etmekte ve toplumlarÄ± olumsuz yÃ¶nde etkilemektedir.\\n\"\"\"\\n\\n# 3. Ã–zetleme iÃ§in giriÅŸ formatÄ±: \\'summarize:\\' Ã¶n ekini ekliyoruz\\ninput_text = f\"summarize: {turkish_text}\"\\n\\n# 4. Tokenizer ile metni encode etme\\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\\n\\n# 5. Modeli kullanarak Ã¶zetleme yapma\\nsummary_ids = model.generate(\\n    input_ids, \\n    max_length=150, \\n    min_length=30, \\n    length_penalty=2.0, \\n    num_beams=4, \\n    early_stopping=True\\n)\\n\\n# 6. Ã–zetlenen metni decode etme\\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\\n\\n# 7. Sonucu yazdÄ±rma\\nprint(\"Ã–zetlenen Metin:\")\\nprint(summary)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "from transformers import MT5Tokenizer, MT5ForConditionalGeneration\n",
        "\n",
        "# 1. Tokenizer ve modelin yÃ¼klenmesi\n",
        "model_name = \"google/mt5-small\"\n",
        "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 2. Ã–zetlenmek istenen TÃ¼rkÃ§e metin\n",
        "turkish_text = \"\"\"\n",
        "Ä°klim deÄŸiÅŸikliÄŸi, kÃ¼resel sÄ±caklÄ±klarÄ±n artÄ±ÅŸÄ±yla birlikte ortaya Ã§Ä±kan Ã§evresel, sosyal ve ekonomik sorunlara neden olmaktadÄ±r.\n",
        "Ã–zellikle kuraklÄ±k, sel ve orman yangÄ±nlarÄ± gibi doÄŸal afetlerin sÄ±klÄ±ÄŸÄ± artarken, tarÄ±msal Ã¼retimde de ciddi dÃ¼ÅŸÃ¼ÅŸler yaÅŸanmaktadÄ±r.\n",
        "Bu durum, gÄ±da gÃ¼venliÄŸini tehdit etmekte ve toplumlarÄ± olumsuz yÃ¶nde etkilemektedir.\n",
        "\"\"\"\n",
        "\n",
        "# 3. Ã–zetleme iÃ§in giriÅŸ formatÄ±: 'summarize:' Ã¶n ekini ekliyoruz\n",
        "input_text = f\"summarize: {turkish_text}\"\n",
        "\n",
        "# 4. Tokenizer ile metni encode etme\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# 5. Modeli kullanarak Ã¶zetleme yapma\n",
        "summary_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=150,\n",
        "    min_length=30,\n",
        "    length_penalty=2.0,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# 6. Ã–zetlenen metni decode etme\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# 7. Sonucu yazdÄ±rma\n",
        "print(\"Ã–zetlenen Metin:\")\n",
        "print(summary)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Kvsu1jtiPV66"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model konfigÃ¼rasyonu\n",
        "mt5_config = AutoConfig.from_pretrained(\n",
        "    \"google/mt5-small\",\n",
        "    max_length=128,\n",
        "    length_penalty=0.6,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=15,\n",
        ")\n",
        "\n",
        "# PyTorch tabanlÄ± modeli yÃ¼kleme ve GPU/CPU'ya taÅŸÄ±ma\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\", config=mt5_config).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kL7j5kNqPV67"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(\n",
        "  tokenizer,\n",
        "  model=model,\n",
        "  return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "o9p6BzTgPV67"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# define function for custom tokenization\n",
        "def tokenize_sentence(arg):\n",
        "  encoded_arg = tokenizer(arg)\n",
        "  return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
        "\n",
        "# define function to get ROUGE scores with custom tokenization\n",
        "def metrics_func(eval_arg):\n",
        "  preds, labels = eval_arg\n",
        "  # Replace -100\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  # Convert id tokens to text\n",
        "  text_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "  text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
        "  # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
        "  text_preds = [(p if p.endswith((\"!\", \"ï¼\", \"?\", \"ï¼Ÿ\", \"ã€‚\")) else p + \"ã€‚\") for p in text_preds]\n",
        "  text_labels = [(l if l.endswith((\"!\", \"ï¼\", \"?\", \"ï¼Ÿ\", \"ã€‚\")) else l + \"ã€‚\") for l in text_labels]\n",
        "  sent_tokenizer_jp = RegexpTokenizer(u'[^!ï¼?ï¼Ÿã€‚]*[!ï¼?ï¼Ÿã€‚]')\n",
        "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
        "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
        "  # compute ROUGE score with custom tokenization\n",
        "  return rouge_metric.compute(\n",
        "    predictions=text_preds,\n",
        "    references=text_labels,\n",
        "    tokenizer=tokenize_sentence\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED_Q-uAc16eV",
        "outputId": "b6b26a49-0a7e-43ce-d38e-ea684b80b8b4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "508khiopPV67",
        "outputId": "b4937020-38fe-448f-f67d-eb8a348b5a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"mt5-summarize-ja\",\n",
        "    log_level=\"error\",\n",
        "    num_train_epochs=5,  # EÄŸitim sÃ¼resini kÄ±saltmak gerekebilir\n",
        "    learning_rate=3e-5,  # Daha dÃ¼ÅŸÃ¼k Ã¶ÄŸrenme oranÄ±, bÃ¼yÃ¼k veri setlerinde genellikle daha iyidir\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=1000,  # Daha fazla warmup adÄ±mÄ±, bÃ¼yÃ¼k veri setleri iÃ§in faydalÄ± olabilir\n",
        "    optim=\"adafactor\",\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=8,  # Batch boyutunu artÄ±rmak daha iyi sonuÃ§ verebilir\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # BÃ¼yÃ¼k bir batch boyutu elde etmek iÃ§in gradient accumulation kullanÄ±mÄ±\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,  # DeÄŸerlendirme adÄ±mlarÄ±nÄ± artÄ±rma\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=128,\n",
        "    save_steps=1000,  # Daha sÄ±k model kaydetme\n",
        "    logging_steps=50,  # Daha az sÄ±k loglama\n",
        "    push_to_hub=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GdDg8SNEPV68",
        "outputId": "a702983b-883b-4942-f042-1261efcf706a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241204_182935-u8gw9xm3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3' target=\"_blank\">mt5-summarize-ja</a></strong> to <a href='https://wandb.ai/buraak380-balikesir-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/buraak380-balikesir-university/huggingface' target=\"_blank\">https://wandb.ai/buraak380-balikesir-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3' target=\"_blank\">https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 24.5112, 'grad_norm': 16774.7421875, 'learning_rate': 1.5e-06, 'epoch': 0.023056083924145484}\n",
            "{'loss': 23.6268, 'grad_norm': 7427.5166015625, 'learning_rate': 3e-06, 'epoch': 0.04611216784829097}\n",
            "{'loss': 22.1511, 'grad_norm': 11378.0224609375, 'learning_rate': 4.5e-06, 'epoch': 0.06916825177243645}\n",
            "{'loss': 20.1197, 'grad_norm': 19247.185546875, 'learning_rate': 6e-06, 'epoch': 0.09222433569658194}\n",
            "{'loss': 17.8633, 'grad_norm': 14236.763671875, 'learning_rate': 7.5e-06, 'epoch': 0.11528041962072742}\n",
            "{'loss': 15.1001, 'grad_norm': 3186.00537109375, 'learning_rate': 9e-06, 'epoch': 0.1383365035448729}\n",
            "{'loss': 12.5646, 'grad_norm': 2478.00537109375, 'learning_rate': 1.05e-05, 'epoch': 0.16139258746901838}\n",
            "{'loss': 10.0196, 'grad_norm': 1175.4456787109375, 'learning_rate': 1.2e-05, 'epoch': 0.18444867139316387}\n",
            "{'loss': 7.8663, 'grad_norm': 529.7356567382812, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.20750475531730936}\n",
            "{'loss': 6.6431, 'grad_norm': 198.30833435058594, 'learning_rate': 1.5e-05, 'epoch': 0.23056083924145485}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 3.2425925731658936, 'eval_rouge1': 0.27868188998239907, 'eval_rouge2': 0.1480487905727444, 'eval_rougeL': 0.21579057046004535, 'eval_rougeLsum': 0.21626552718006642, 'eval_runtime': 33.5535, 'eval_samples_per_second': 0.596, 'eval_steps_per_second': 0.149, 'epoch': 0.23056083924145485}\n",
            "{'loss': 5.8539, 'grad_norm': 146.40818786621094, 'learning_rate': 1.65e-05, 'epoch': 0.2536169231656003}\n",
            "{'loss': 5.1889, 'grad_norm': 111.25946044921875, 'learning_rate': 1.8e-05, 'epoch': 0.2766730070897458}\n",
            "{'loss': 4.7205, 'grad_norm': 1226.7098388671875, 'learning_rate': 1.95e-05, 'epoch': 0.2997290910138913}\n",
            "{'loss': 4.4035, 'grad_norm': 27.96617317199707, 'learning_rate': 2.1e-05, 'epoch': 0.32278517493803677}\n",
            "{'loss': 4.227, 'grad_norm': 98.8541259765625, 'learning_rate': 2.25e-05, 'epoch': 0.34584125886218225}\n",
            "{'loss': 3.9979, 'grad_norm': 18.958141326904297, 'learning_rate': 2.4e-05, 'epoch': 0.36889734278632774}\n",
            "{'loss': 3.901, 'grad_norm': 17.45825958251953, 'learning_rate': 2.55e-05, 'epoch': 0.39195342671047323}\n",
            "{'loss': 3.7696, 'grad_norm': 19.302753448486328, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.4150095106346187}\n",
            "{'loss': 3.723, 'grad_norm': 15.533737182617188, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.4380655945587642}\n",
            "{'loss': 3.6061, 'grad_norm': 16.410594940185547, 'learning_rate': 3e-05, 'epoch': 0.4611216784829097}\n",
            "{'eval_loss': 2.9723572731018066, 'eval_rouge1': 0.30271807882962576, 'eval_rouge2': 0.1758935949790496, 'eval_rougeL': 0.2721390309032612, 'eval_rougeLsum': 0.27298056001547855, 'eval_runtime': 13.904, 'eval_samples_per_second': 1.438, 'eval_steps_per_second': 0.36, 'epoch': 0.4611216784829097}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'num_beams': 15, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.5721, 'grad_norm': 17.894153594970703, 'learning_rate': 2.9847560975609756e-05, 'epoch': 0.4841777624070552}\n",
            "{'loss': 3.5084, 'grad_norm': 16.740772247314453, 'learning_rate': 2.9695121951219515e-05, 'epoch': 0.5072338463312006}\n",
            "{'loss': 3.4453, 'grad_norm': 14.236841201782227, 'learning_rate': 2.954268292682927e-05, 'epoch': 0.5302899302553461}\n",
            "{'loss': 3.3784, 'grad_norm': 14.119400978088379, 'learning_rate': 2.9390243902439022e-05, 'epoch': 0.5533460141794916}\n",
            "{'loss': 3.3471, 'grad_norm': 14.839422225952148, 'learning_rate': 2.923780487804878e-05, 'epoch': 0.5764020981036371}\n",
            "{'loss': 3.3048, 'grad_norm': 18.75555992126465, 'learning_rate': 2.9085365853658536e-05, 'epoch': 0.5994581820277826}\n",
            "{'loss': 3.2665, 'grad_norm': 14.308640480041504, 'learning_rate': 2.8932926829268295e-05, 'epoch': 0.622514265951928}\n",
            "{'loss': 3.191, 'grad_norm': 12.731827735900879, 'learning_rate': 2.878048780487805e-05, 'epoch': 0.6455703498760735}\n",
            "{'loss': 3.1721, 'grad_norm': 12.812121391296387, 'learning_rate': 2.8628048780487805e-05, 'epoch': 0.668626433800219}\n",
            "{'loss': 3.1435, 'grad_norm': 11.910759925842285, 'learning_rate': 2.8475609756097564e-05, 'epoch': 0.6916825177243645}\n",
            "{'eval_loss': 2.671978235244751, 'eval_rouge1': 0.37050786927389445, 'eval_rouge2': 0.2286977597882208, 'eval_rougeL': 0.3337544872995933, 'eval_rougeLsum': 0.3346952790445227, 'eval_runtime': 15.0581, 'eval_samples_per_second': 1.328, 'eval_steps_per_second': 0.332, 'epoch': 0.6916825177243645}\n",
            "{'loss': 3.1082, 'grad_norm': 13.50170612335205, 'learning_rate': 2.832317073170732e-05, 'epoch': 0.71473860164851}\n",
            "{'loss': 3.072, 'grad_norm': 14.895974159240723, 'learning_rate': 2.817073170731707e-05, 'epoch': 0.7377946855726555}\n",
            "{'loss': 3.0587, 'grad_norm': 13.28650188446045, 'learning_rate': 2.801829268292683e-05, 'epoch': 0.760850769496801}\n",
            "{'loss': 3.0329, 'grad_norm': 26.724464416503906, 'learning_rate': 2.7865853658536585e-05, 'epoch': 0.7839068534209465}\n",
            "{'loss': 3.0199, 'grad_norm': 11.835593223571777, 'learning_rate': 2.7713414634146344e-05, 'epoch': 0.806962937345092}\n",
            "{'loss': 2.9894, 'grad_norm': 13.087066650390625, 'learning_rate': 2.75609756097561e-05, 'epoch': 0.8300190212692374}\n",
            "{'loss': 2.9879, 'grad_norm': 12.32600212097168, 'learning_rate': 2.7408536585365854e-05, 'epoch': 0.8530751051933829}\n",
            "{'loss': 2.9778, 'grad_norm': 11.856870651245117, 'learning_rate': 2.7256097560975613e-05, 'epoch': 0.8761311891175284}\n",
            "{'loss': 2.9662, 'grad_norm': 14.248811721801758, 'learning_rate': 2.7103658536585365e-05, 'epoch': 0.8991872730416739}\n",
            "{'loss': 2.9001, 'grad_norm': 15.733882904052734, 'learning_rate': 2.695121951219512e-05, 'epoch': 0.9222433569658194}\n",
            "{'eval_loss': 2.5733323097229004, 'eval_rouge1': 0.39693081747804754, 'eval_rouge2': 0.25594390684733925, 'eval_rougeL': 0.35755217057451005, 'eval_rougeLsum': 0.358118159391117, 'eval_runtime': 16.9776, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 0.295, 'epoch': 0.9222433569658194}\n",
            "{'loss': 2.9093, 'grad_norm': 12.118583679199219, 'learning_rate': 2.679878048780488e-05, 'epoch': 0.9452994408899649}\n",
            "{'loss': 2.8922, 'grad_norm': 11.997276306152344, 'learning_rate': 2.6646341463414634e-05, 'epoch': 0.9683555248141104}\n",
            "{'loss': 2.8862, 'grad_norm': 12.037343978881836, 'learning_rate': 2.6493902439024393e-05, 'epoch': 0.9914116087382558}\n",
            "{'loss': 2.9021, 'grad_norm': 30.4051570892334, 'learning_rate': 2.6341463414634148e-05, 'epoch': 1.0146406132918324}\n",
            "{'loss': 2.8793, 'grad_norm': 12.55605697631836, 'learning_rate': 2.6189024390243903e-05, 'epoch': 1.0376966972159778}\n",
            "{'loss': 2.8192, 'grad_norm': 12.40013313293457, 'learning_rate': 2.603658536585366e-05, 'epoch': 1.0607527811401234}\n",
            "{'loss': 2.7986, 'grad_norm': 12.453566551208496, 'learning_rate': 2.5884146341463414e-05, 'epoch': 1.0838088650642688}\n",
            "{'loss': 2.7801, 'grad_norm': 12.573058128356934, 'learning_rate': 2.573170731707317e-05, 'epoch': 1.1068649489884144}\n",
            "{'loss': 2.8358, 'grad_norm': 11.075135231018066, 'learning_rate': 2.5579268292682928e-05, 'epoch': 1.1299210329125597}\n",
            "{'loss': 2.82, 'grad_norm': 12.062179565429688, 'learning_rate': 2.5426829268292683e-05, 'epoch': 1.1529771168367053}\n",
            "{'eval_loss': 2.488537311553955, 'eval_rouge1': 0.39003671071858587, 'eval_rouge2': 0.25675818407234635, 'eval_rougeL': 0.3583678841990378, 'eval_rougeLsum': 0.3589805907802068, 'eval_runtime': 17.2468, 'eval_samples_per_second': 1.16, 'eval_steps_per_second': 0.29, 'epoch': 1.1529771168367053}\n",
            "{'loss': 2.8226, 'grad_norm': 10.972772598266602, 'learning_rate': 2.527439024390244e-05, 'epoch': 1.1760332007608507}\n",
            "{'loss': 2.8051, 'grad_norm': 11.943621635437012, 'learning_rate': 2.5121951219512197e-05, 'epoch': 1.1990892846849963}\n",
            "{'loss': 2.7673, 'grad_norm': 12.048783302307129, 'learning_rate': 2.4969512195121952e-05, 'epoch': 1.2221453686091417}\n",
            "{'loss': 2.7717, 'grad_norm': 19.191055297851562, 'learning_rate': 2.4817073170731708e-05, 'epoch': 1.2452014525332873}\n",
            "{'loss': 2.7859, 'grad_norm': 14.062714576721191, 'learning_rate': 2.4664634146341463e-05, 'epoch': 1.2682575364574327}\n",
            "{'loss': 2.741, 'grad_norm': 12.391724586486816, 'learning_rate': 2.4512195121951218e-05, 'epoch': 1.2913136203815783}\n",
            "{'loss': 2.7456, 'grad_norm': 10.558584213256836, 'learning_rate': 2.4359756097560977e-05, 'epoch': 1.3143697043057236}\n",
            "{'loss': 2.7459, 'grad_norm': 10.626717567443848, 'learning_rate': 2.4207317073170732e-05, 'epoch': 1.3374257882298692}\n",
            "{'loss': 2.7152, 'grad_norm': 10.615509033203125, 'learning_rate': 2.405487804878049e-05, 'epoch': 1.3604818721540146}\n",
            "{'loss': 2.7095, 'grad_norm': 10.243266105651855, 'learning_rate': 2.3902439024390246e-05, 'epoch': 1.3835379560781602}\n",
            "{'eval_loss': 2.484046697616577, 'eval_rouge1': 0.37873493416895726, 'eval_rouge2': 0.24486176201486176, 'eval_rougeL': 0.33953489873993603, 'eval_rougeLsum': 0.33928699915835925, 'eval_runtime': 17.6459, 'eval_samples_per_second': 1.133, 'eval_steps_per_second': 0.283, 'epoch': 1.3835379560781602}\n",
            "{'loss': 2.7333, 'grad_norm': 10.008904457092285, 'learning_rate': 2.3749999999999998e-05, 'epoch': 1.4065940400023056}\n",
            "{'loss': 2.7013, 'grad_norm': 11.850410461425781, 'learning_rate': 2.3597560975609757e-05, 'epoch': 1.429650123926451}\n",
            "{'loss': 2.7116, 'grad_norm': 12.326692581176758, 'learning_rate': 2.3445121951219512e-05, 'epoch': 1.4527062078505966}\n",
            "{'loss': 2.7024, 'grad_norm': 9.918496131896973, 'learning_rate': 2.3292682926829267e-05, 'epoch': 1.4757622917747422}\n",
            "{'loss': 2.6715, 'grad_norm': 14.097129821777344, 'learning_rate': 2.3140243902439026e-05, 'epoch': 1.4988183756988875}\n",
            "{'loss': 2.6666, 'grad_norm': 11.665379524230957, 'learning_rate': 2.298780487804878e-05, 'epoch': 1.521874459623033}\n",
            "{'loss': 2.6709, 'grad_norm': 12.764392852783203, 'learning_rate': 2.283536585365854e-05, 'epoch': 1.5449305435471785}\n",
            "{'loss': 2.679, 'grad_norm': 11.160256385803223, 'learning_rate': 2.2682926829268295e-05, 'epoch': 1.5679866274713241}\n",
            "{'loss': 2.6482, 'grad_norm': 9.983196258544922, 'learning_rate': 2.2530487804878047e-05, 'epoch': 1.5910427113954695}\n",
            "{'loss': 2.63, 'grad_norm': 11.062216758728027, 'learning_rate': 2.2378048780487806e-05, 'epoch': 1.6140987953196149}\n",
            "{'eval_loss': 2.4477429389953613, 'eval_rouge1': 0.39323026525434823, 'eval_rouge2': 0.2550425344591487, 'eval_rougeL': 0.35225490694804074, 'eval_rougeLsum': 0.35383491119368793, 'eval_runtime': 18.2138, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 0.275, 'epoch': 1.6140987953196149}\n",
            "{'loss': 2.6592, 'grad_norm': 11.190690994262695, 'learning_rate': 2.222560975609756e-05, 'epoch': 1.6371548792437605}\n",
            "{'loss': 2.6427, 'grad_norm': 12.247944831848145, 'learning_rate': 2.2073170731707316e-05, 'epoch': 1.660210963167906}\n",
            "{'loss': 2.6491, 'grad_norm': 12.402313232421875, 'learning_rate': 2.1920731707317075e-05, 'epoch': 1.6832670470920514}\n",
            "{'loss': 2.6353, 'grad_norm': 11.387008666992188, 'learning_rate': 2.176829268292683e-05, 'epoch': 1.7063231310161968}\n",
            "{'loss': 2.6329, 'grad_norm': 11.37997055053711, 'learning_rate': 2.161585365853659e-05, 'epoch': 1.7293792149403424}\n",
            "{'loss': 2.6225, 'grad_norm': 12.697090148925781, 'learning_rate': 2.146341463414634e-05, 'epoch': 1.752435298864488}\n",
            "{'loss': 2.6273, 'grad_norm': 10.799772262573242, 'learning_rate': 2.1310975609756096e-05, 'epoch': 1.7754913827886334}\n",
            "{'loss': 2.6479, 'grad_norm': 10.632664680480957, 'learning_rate': 2.1158536585365855e-05, 'epoch': 1.7985474667127788}\n",
            "{'loss': 2.6141, 'grad_norm': 10.648881912231445, 'learning_rate': 2.100609756097561e-05, 'epoch': 1.8216035506369244}\n",
            "{'loss': 2.6261, 'grad_norm': 10.205967903137207, 'learning_rate': 2.0853658536585365e-05, 'epoch': 1.84465963456107}\n",
            "{'eval_loss': 2.3877484798431396, 'eval_rouge1': 0.39449659037124907, 'eval_rouge2': 0.25753367282579664, 'eval_rougeL': 0.3537852554455278, 'eval_rougeLsum': 0.3548470875555577, 'eval_runtime': 17.2095, 'eval_samples_per_second': 1.162, 'eval_steps_per_second': 0.291, 'epoch': 1.84465963456107}\n",
            "{'loss': 2.6014, 'grad_norm': 10.895798683166504, 'learning_rate': 2.0701219512195124e-05, 'epoch': 1.8677157184852153}\n",
            "{'loss': 2.5797, 'grad_norm': 10.948487281799316, 'learning_rate': 2.054878048780488e-05, 'epoch': 1.8907718024093607}\n",
            "{'loss': 2.5615, 'grad_norm': 13.712175369262695, 'learning_rate': 2.0396341463414635e-05, 'epoch': 1.913827886333506}\n",
            "{'loss': 2.56, 'grad_norm': 10.63505744934082, 'learning_rate': 2.024390243902439e-05, 'epoch': 1.9368839702576517}\n",
            "{'loss': 2.5922, 'grad_norm': 9.867226600646973, 'learning_rate': 2.0091463414634145e-05, 'epoch': 1.9599400541817973}\n",
            "{'loss': 2.6018, 'grad_norm': 10.09182071685791, 'learning_rate': 1.9939024390243904e-05, 'epoch': 1.9829961381059427}\n",
            "{'loss': 2.5689, 'grad_norm': 12.514313697814941, 'learning_rate': 1.978658536585366e-05, 'epoch': 2.0062251426595195}\n",
            "{'loss': 2.5797, 'grad_norm': 11.642801284790039, 'learning_rate': 1.9634146341463414e-05, 'epoch': 2.029281226583665}\n",
            "{'loss': 2.5515, 'grad_norm': 10.051085472106934, 'learning_rate': 1.9481707317073173e-05, 'epoch': 2.05233731050781}\n",
            "{'loss': 2.5485, 'grad_norm': 12.150893211364746, 'learning_rate': 1.9329268292682928e-05, 'epoch': 2.0753933944319556}\n",
            "{'eval_loss': 2.390402317047119, 'eval_rouge1': 0.4010516806697192, 'eval_rouge2': 0.2606489317924252, 'eval_rougeL': 0.35649923689976215, 'eval_rougeLsum': 0.35725713733756825, 'eval_runtime': 18.4574, 'eval_samples_per_second': 1.084, 'eval_steps_per_second': 0.271, 'epoch': 2.0753933944319556}\n",
            "{'loss': 2.5916, 'grad_norm': 10.23307991027832, 'learning_rate': 1.9176829268292684e-05, 'epoch': 2.0984494783561014}\n",
            "{'loss': 2.5922, 'grad_norm': 10.200557708740234, 'learning_rate': 1.902439024390244e-05, 'epoch': 2.121505562280247}\n",
            "{'loss': 2.5395, 'grad_norm': 11.209213256835938, 'learning_rate': 1.8871951219512194e-05, 'epoch': 2.144561646204392}\n",
            "{'loss': 2.5569, 'grad_norm': 10.434911727905273, 'learning_rate': 1.8719512195121953e-05, 'epoch': 2.1676177301285375}\n",
            "{'loss': 2.5531, 'grad_norm': 10.402155876159668, 'learning_rate': 1.8567073170731708e-05, 'epoch': 2.1906738140526834}\n",
            "{'loss': 2.5613, 'grad_norm': 12.685647964477539, 'learning_rate': 1.8414634146341463e-05, 'epoch': 2.2137298979768287}\n",
            "{'loss': 2.5418, 'grad_norm': 11.835286140441895, 'learning_rate': 1.8262195121951222e-05, 'epoch': 2.236785981900974}\n",
            "{'loss': 2.5361, 'grad_norm': 14.57607364654541, 'learning_rate': 1.8109756097560974e-05, 'epoch': 2.2598420658251195}\n",
            "{'loss': 2.5637, 'grad_norm': 9.632112503051758, 'learning_rate': 1.7957317073170733e-05, 'epoch': 2.282898149749265}\n",
            "{'loss': 2.524, 'grad_norm': 10.669240951538086, 'learning_rate': 1.7804878048780488e-05, 'epoch': 2.3059542336734107}\n",
            "{'eval_loss': 2.3560826778411865, 'eval_rouge1': 0.3992679171477902, 'eval_rouge2': 0.2575042612949556, 'eval_rougeL': 0.35454723314978964, 'eval_rougeLsum': 0.3552318329911385, 'eval_runtime': 18.5737, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.269, 'epoch': 2.3059542336734107}\n",
            "{'loss': 2.5353, 'grad_norm': 10.125628471374512, 'learning_rate': 1.7652439024390243e-05, 'epoch': 2.329010317597556}\n",
            "{'loss': 2.5441, 'grad_norm': 10.290915489196777, 'learning_rate': 1.7500000000000002e-05, 'epoch': 2.3520664015217014}\n",
            "{'loss': 2.5743, 'grad_norm': 9.975162506103516, 'learning_rate': 1.7347560975609757e-05, 'epoch': 2.3751224854458473}\n",
            "{'loss': 2.5028, 'grad_norm': 10.689591407775879, 'learning_rate': 1.7195121951219512e-05, 'epoch': 2.3981785693699926}\n",
            "{'loss': 2.5274, 'grad_norm': 10.335311889648438, 'learning_rate': 1.704268292682927e-05, 'epoch': 2.421234653294138}\n",
            "{'loss': 2.484, 'grad_norm': 10.17721176147461, 'learning_rate': 1.6890243902439023e-05, 'epoch': 2.4442907372182834}\n",
            "{'loss': 2.5069, 'grad_norm': 10.193964004516602, 'learning_rate': 1.673780487804878e-05, 'epoch': 2.4673468211424288}\n",
            "{'loss': 2.528, 'grad_norm': 10.874619483947754, 'learning_rate': 1.6585365853658537e-05, 'epoch': 2.4904029050665746}\n",
            "{'loss': 2.5267, 'grad_norm': 10.26282024383545, 'learning_rate': 1.6432926829268292e-05, 'epoch': 2.51345898899072}\n",
            "{'loss': 2.5143, 'grad_norm': 14.831817626953125, 'learning_rate': 1.628048780487805e-05, 'epoch': 2.5365150729148653}\n",
            "{'eval_loss': 2.341432571411133, 'eval_rouge1': 0.39974184941599744, 'eval_rouge2': 0.26026352958285737, 'eval_rougeL': 0.35623961335591436, 'eval_rougeLsum': 0.3564560787247349, 'eval_runtime': 18.2298, 'eval_samples_per_second': 1.097, 'eval_steps_per_second': 0.274, 'epoch': 2.5365150729148653}\n",
            "{'loss': 2.507, 'grad_norm': 10.934913635253906, 'learning_rate': 1.6128048780487806e-05, 'epoch': 2.559571156839011}\n",
            "{'loss': 2.4973, 'grad_norm': 9.496092796325684, 'learning_rate': 1.597560975609756e-05, 'epoch': 2.5826272407631565}\n",
            "{'loss': 2.5138, 'grad_norm': 11.387688636779785, 'learning_rate': 1.5823170731707317e-05, 'epoch': 2.605683324687302}\n",
            "{'loss': 2.5045, 'grad_norm': 10.355055809020996, 'learning_rate': 1.5670731707317072e-05, 'epoch': 2.6287394086114473}\n",
            "{'loss': 2.5228, 'grad_norm': 11.655776977539062, 'learning_rate': 1.551829268292683e-05, 'epoch': 2.6517954925355927}\n",
            "{'loss': 2.5229, 'grad_norm': 53.177574157714844, 'learning_rate': 1.5365853658536586e-05, 'epoch': 2.6748515764597385}\n",
            "{'loss': 2.4785, 'grad_norm': 10.859707832336426, 'learning_rate': 1.5213414634146341e-05, 'epoch': 2.697907660383884}\n",
            "{'loss': 2.4968, 'grad_norm': 9.2811918258667, 'learning_rate': 1.5060975609756098e-05, 'epoch': 2.7209637443080292}\n",
            "{'loss': 2.4839, 'grad_norm': 10.754032135009766, 'learning_rate': 1.4908536585365854e-05, 'epoch': 2.7440198282321746}\n",
            "{'loss': 2.5342, 'grad_norm': 10.507895469665527, 'learning_rate': 1.475609756097561e-05, 'epoch': 2.7670759121563204}\n",
            "{'eval_loss': 2.3251986503601074, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 18.5867, 'eval_samples_per_second': 1.076, 'eval_steps_per_second': 0.269, 'epoch': 2.7670759121563204}\n",
            "{'loss': 2.4711, 'grad_norm': 10.149398803710938, 'learning_rate': 1.4603658536585368e-05, 'epoch': 2.790131996080466}\n",
            "{'loss': 2.4846, 'grad_norm': 10.495892524719238, 'learning_rate': 1.4451219512195121e-05, 'epoch': 2.813188080004611}\n",
            "{'loss': 2.4918, 'grad_norm': 10.914058685302734, 'learning_rate': 1.4298780487804878e-05, 'epoch': 2.8362441639287566}\n",
            "{'loss': 2.4887, 'grad_norm': 9.305901527404785, 'learning_rate': 1.4146341463414635e-05, 'epoch': 2.859300247852902}\n",
            "{'loss': 2.4765, 'grad_norm': 10.311554908752441, 'learning_rate': 1.3993902439024392e-05, 'epoch': 2.8823563317770478}\n",
            "{'loss': 2.4838, 'grad_norm': 9.935501098632812, 'learning_rate': 1.3841463414634146e-05, 'epoch': 2.905412415701193}\n",
            "{'loss': 2.4697, 'grad_norm': 9.06320571899414, 'learning_rate': 1.3689024390243903e-05, 'epoch': 2.9284684996253385}\n",
            "{'loss': 2.4991, 'grad_norm': 10.720715522766113, 'learning_rate': 1.353658536585366e-05, 'epoch': 2.9515245835494843}\n",
            "{'loss': 2.4778, 'grad_norm': 9.226786613464355, 'learning_rate': 1.3384146341463417e-05, 'epoch': 2.9745806674736297}\n",
            "{'loss': 2.4855, 'grad_norm': 9.26325798034668, 'learning_rate': 1.323170731707317e-05, 'epoch': 2.997636751397775}\n",
            "{'eval_loss': 2.3187615871429443, 'eval_rouge1': 0.3826433934544623, 'eval_rouge2': 0.24462022641671638, 'eval_rougeL': 0.3422076639299248, 'eval_rougeLsum': 0.3428772780911252, 'eval_runtime': 19.3079, 'eval_samples_per_second': 1.036, 'eval_steps_per_second': 0.259, 'epoch': 2.997636751397775}\n",
            "{'loss': 2.4724, 'grad_norm': 10.1837797164917, 'learning_rate': 1.3079268292682927e-05, 'epoch': 3.020865755951352}\n",
            "{'loss': 2.4389, 'grad_norm': 9.090506553649902, 'learning_rate': 1.2926829268292684e-05, 'epoch': 3.0439218398754972}\n",
            "{'loss': 2.4994, 'grad_norm': 10.189800262451172, 'learning_rate': 1.277439024390244e-05, 'epoch': 3.0669779237996426}\n",
            "{'loss': 2.4831, 'grad_norm': 10.558107376098633, 'learning_rate': 1.2621951219512195e-05, 'epoch': 3.090034007723788}\n",
            "{'loss': 2.4505, 'grad_norm': 11.447772979736328, 'learning_rate': 1.2469512195121952e-05, 'epoch': 3.1130900916479334}\n",
            "{'loss': 2.4395, 'grad_norm': 11.130088806152344, 'learning_rate': 1.2317073170731709e-05, 'epoch': 3.136146175572079}\n",
            "{'loss': 2.441, 'grad_norm': 12.401923179626465, 'learning_rate': 1.2164634146341464e-05, 'epoch': 3.1592022594962246}\n",
            "{'loss': 2.4468, 'grad_norm': 26.60920524597168, 'learning_rate': 1.201219512195122e-05, 'epoch': 3.18225834342037}\n",
            "{'loss': 2.4667, 'grad_norm': 9.639086723327637, 'learning_rate': 1.1859756097560976e-05, 'epoch': 3.2053144273445153}\n",
            "{'loss': 2.4637, 'grad_norm': 9.803449630737305, 'learning_rate': 1.1707317073170733e-05, 'epoch': 3.228370511268661}\n",
            "{'eval_loss': 2.2940685749053955, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 17.6361, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 3.228370511268661}\n",
            "{'loss': 2.4859, 'grad_norm': 10.089349746704102, 'learning_rate': 1.1554878048780488e-05, 'epoch': 3.2514265951928065}\n",
            "{'loss': 2.5076, 'grad_norm': 9.369735717773438, 'learning_rate': 1.1402439024390244e-05, 'epoch': 3.274482679116952}\n",
            "{'loss': 2.4329, 'grad_norm': 11.167649269104004, 'learning_rate': 1.125e-05, 'epoch': 3.2975387630410973}\n",
            "{'loss': 2.4434, 'grad_norm': 9.39116096496582, 'learning_rate': 1.1097560975609756e-05, 'epoch': 3.320594846965243}\n",
            "{'loss': 2.4462, 'grad_norm': 10.141561508178711, 'learning_rate': 1.0945121951219511e-05, 'epoch': 3.3436509308893885}\n",
            "{'loss': 2.467, 'grad_norm': 10.090742111206055, 'learning_rate': 1.0792682926829268e-05, 'epoch': 3.366707014813534}\n",
            "{'loss': 2.4683, 'grad_norm': 10.877820014953613, 'learning_rate': 1.0640243902439025e-05, 'epoch': 3.3897630987376792}\n",
            "{'loss': 2.431, 'grad_norm': 10.741387367248535, 'learning_rate': 1.048780487804878e-05, 'epoch': 3.412819182661825}\n",
            "{'loss': 2.4201, 'grad_norm': 10.327797889709473, 'learning_rate': 1.0335365853658536e-05, 'epoch': 3.4358752665859704}\n",
            "{'loss': 2.4598, 'grad_norm': 9.451332092285156, 'learning_rate': 1.0182926829268293e-05, 'epoch': 3.458931350510116}\n",
            "{'eval_loss': 2.3005118370056152, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 19.163, 'eval_samples_per_second': 1.044, 'eval_steps_per_second': 0.261, 'epoch': 3.458931350510116}\n",
            "{'loss': 2.4697, 'grad_norm': 12.237128257751465, 'learning_rate': 1.003048780487805e-05, 'epoch': 3.481987434434261}\n",
            "{'loss': 2.4419, 'grad_norm': 14.023435592651367, 'learning_rate': 9.878048780487805e-06, 'epoch': 3.5050435183584066}\n",
            "{'loss': 2.4625, 'grad_norm': 9.967162132263184, 'learning_rate': 9.72560975609756e-06, 'epoch': 3.5280996022825524}\n",
            "{'loss': 2.4552, 'grad_norm': 9.740726470947266, 'learning_rate': 9.573170731707317e-06, 'epoch': 3.5511556862066977}\n",
            "{'loss': 2.4468, 'grad_norm': 9.465620040893555, 'learning_rate': 9.420731707317074e-06, 'epoch': 3.574211770130843}\n",
            "{'loss': 2.4497, 'grad_norm': 9.205748558044434, 'learning_rate': 9.26829268292683e-06, 'epoch': 3.597267854054989}\n",
            "{'loss': 2.4587, 'grad_norm': 9.884926795959473, 'learning_rate': 9.115853658536585e-06, 'epoch': 3.6203239379791343}\n",
            "{'loss': 2.4043, 'grad_norm': 9.662129402160645, 'learning_rate': 8.963414634146342e-06, 'epoch': 3.6433800219032797}\n",
            "{'loss': 2.4308, 'grad_norm': 10.007548332214355, 'learning_rate': 8.810975609756097e-06, 'epoch': 3.666436105827425}\n",
            "{'loss': 2.4293, 'grad_norm': 10.888378143310547, 'learning_rate': 8.658536585365854e-06, 'epoch': 3.6894921897515705}\n",
            "{'eval_loss': 2.2994425296783447, 'eval_rouge1': 0.377953901914031, 'eval_rouge2': 0.23684847463864683, 'eval_rougeL': 0.33664871347080916, 'eval_rougeLsum': 0.3373560058316624, 'eval_runtime': 19.0752, 'eval_samples_per_second': 1.048, 'eval_steps_per_second': 0.262, 'epoch': 3.6894921897515705}\n",
            "{'loss': 2.4329, 'grad_norm': 11.634408950805664, 'learning_rate': 8.50609756097561e-06, 'epoch': 3.7125482736757163}\n",
            "{'loss': 2.4227, 'grad_norm': 10.160643577575684, 'learning_rate': 8.353658536585366e-06, 'epoch': 3.7356043575998616}\n",
            "{'loss': 2.4227, 'grad_norm': 10.441740989685059, 'learning_rate': 8.201219512195122e-06, 'epoch': 3.758660441524007}\n",
            "{'loss': 2.4435, 'grad_norm': 11.819329261779785, 'learning_rate': 8.048780487804879e-06, 'epoch': 3.781716525448153}\n",
            "{'loss': 2.4102, 'grad_norm': 11.195652961730957, 'learning_rate': 7.896341463414634e-06, 'epoch': 3.804772609372298}\n",
            "{'loss': 2.4481, 'grad_norm': 10.415328025817871, 'learning_rate': 7.743902439024391e-06, 'epoch': 3.8278286932964436}\n",
            "{'loss': 2.412, 'grad_norm': 10.08780288696289, 'learning_rate': 7.591463414634147e-06, 'epoch': 3.850884777220589}\n",
            "{'loss': 2.4007, 'grad_norm': 8.837145805358887, 'learning_rate': 7.439024390243902e-06, 'epoch': 3.8739408611447343}\n",
            "{'loss': 2.4471, 'grad_norm': 10.929951667785645, 'learning_rate': 7.2865853658536584e-06, 'epoch': 3.89699694506888}\n",
            "{'loss': 2.4398, 'grad_norm': 9.844974517822266, 'learning_rate': 7.1341463414634146e-06, 'epoch': 3.9200530289930255}\n",
            "{'eval_loss': 2.287888288497925, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 18.3855, 'eval_samples_per_second': 1.088, 'eval_steps_per_second': 0.272, 'epoch': 3.9200530289930255}\n",
            "{'loss': 2.4166, 'grad_norm': 11.272649765014648, 'learning_rate': 6.981707317073171e-06, 'epoch': 3.943109112917171}\n",
            "{'loss': 2.4122, 'grad_norm': 11.874253273010254, 'learning_rate': 6.829268292682927e-06, 'epoch': 3.9661651968413167}\n",
            "{'loss': 2.4452, 'grad_norm': 10.70010757446289, 'learning_rate': 6.676829268292683e-06, 'epoch': 3.989221280765462}\n",
            "{'loss': 2.4246, 'grad_norm': 10.758524894714355, 'learning_rate': 6.524390243902439e-06, 'epoch': 4.012450285319039}\n",
            "{'loss': 2.417, 'grad_norm': 11.2822265625, 'learning_rate': 6.371951219512195e-06, 'epoch': 4.035506369243184}\n",
            "{'loss': 2.4147, 'grad_norm': 9.360004425048828, 'learning_rate': 6.219512195121951e-06, 'epoch': 4.05856245316733}\n",
            "{'loss': 2.4111, 'grad_norm': 11.416108131408691, 'learning_rate': 6.0670731707317075e-06, 'epoch': 4.081618537091475}\n",
            "{'loss': 2.382, 'grad_norm': 11.492987632751465, 'learning_rate': 5.914634146341464e-06, 'epoch': 4.10467462101562}\n",
            "{'loss': 2.4282, 'grad_norm': 9.39499568939209, 'learning_rate': 5.76219512195122e-06, 'epoch': 4.127730704939766}\n",
            "{'loss': 2.4591, 'grad_norm': 11.820181846618652, 'learning_rate': 5.609756097560976e-06, 'epoch': 4.150786788863911}\n",
            "{'eval_loss': 2.279902696609497, 'eval_rouge1': 0.37831667522525936, 'eval_rouge2': 0.23872561084526855, 'eval_rougeL': 0.33878716809435383, 'eval_rougeLsum': 0.33887650192618574, 'eval_runtime': 18.9271, 'eval_samples_per_second': 1.057, 'eval_steps_per_second': 0.264, 'epoch': 4.150786788863911}\n",
            "{'loss': 2.4303, 'grad_norm': 9.737497329711914, 'learning_rate': 5.457317073170732e-06, 'epoch': 4.1738428727880565}\n",
            "{'loss': 2.3994, 'grad_norm': 9.733914375305176, 'learning_rate': 5.304878048780487e-06, 'epoch': 4.196898956712203}\n",
            "{'loss': 2.3995, 'grad_norm': 10.40052318572998, 'learning_rate': 5.152439024390244e-06, 'epoch': 4.219955040636348}\n",
            "{'loss': 2.395, 'grad_norm': 9.013148307800293, 'learning_rate': 4.9999999999999996e-06, 'epoch': 4.243011124560494}\n",
            "{'loss': 2.3975, 'grad_norm': 11.799115180969238, 'learning_rate': 4.8475609756097565e-06, 'epoch': 4.266067208484639}\n",
            "{'loss': 2.4414, 'grad_norm': 9.795778274536133, 'learning_rate': 4.695121951219512e-06, 'epoch': 4.289123292408784}\n",
            "{'loss': 2.4133, 'grad_norm': 9.973028182983398, 'learning_rate': 4.542682926829269e-06, 'epoch': 4.31217937633293}\n",
            "{'loss': 2.4078, 'grad_norm': 11.599930763244629, 'learning_rate': 4.390243902439024e-06, 'epoch': 4.335235460257075}\n",
            "{'loss': 2.4304, 'grad_norm': 9.418218612670898, 'learning_rate': 4.237804878048781e-06, 'epoch': 4.3582915441812204}\n",
            "{'loss': 2.4195, 'grad_norm': 9.966973304748535, 'learning_rate': 4.085365853658536e-06, 'epoch': 4.381347628105367}\n",
            "{'eval_loss': 2.2772135734558105, 'eval_rouge1': 0.38521104054340516, 'eval_rouge2': 0.24675068563270325, 'eval_rougeL': 0.3406360353128802, 'eval_rougeLsum': 0.34129019729203425, 'eval_runtime': 18.4795, 'eval_samples_per_second': 1.082, 'eval_steps_per_second': 0.271, 'epoch': 4.381347628105367}\n",
            "{'loss': 2.4128, 'grad_norm': 11.779458999633789, 'learning_rate': 3.932926829268293e-06, 'epoch': 4.404403712029512}\n",
            "{'loss': 2.3996, 'grad_norm': 10.371357917785645, 'learning_rate': 3.7804878048780486e-06, 'epoch': 4.4274597959536575}\n",
            "{'loss': 2.4129, 'grad_norm': 8.527364730834961, 'learning_rate': 3.628048780487805e-06, 'epoch': 4.450515879877803}\n",
            "{'loss': 2.4197, 'grad_norm': 10.543158531188965, 'learning_rate': 3.4756097560975613e-06, 'epoch': 4.473571963801948}\n",
            "{'loss': 2.4183, 'grad_norm': 9.811819076538086, 'learning_rate': 3.3231707317073174e-06, 'epoch': 4.496628047726094}\n",
            "{'loss': 2.3847, 'grad_norm': 8.850773811340332, 'learning_rate': 3.1707317073170736e-06, 'epoch': 4.519684131650239}\n",
            "{'loss': 2.4466, 'grad_norm': 9.19994068145752, 'learning_rate': 3.0182926829268297e-06, 'epoch': 4.542740215574384}\n",
            "{'loss': 2.4339, 'grad_norm': 10.871662139892578, 'learning_rate': 2.865853658536586e-06, 'epoch': 4.56579629949853}\n",
            "{'loss': 2.4027, 'grad_norm': 10.699763298034668, 'learning_rate': 2.7134146341463415e-06, 'epoch': 4.588852383422676}\n",
            "{'loss': 2.4256, 'grad_norm': 10.620777130126953, 'learning_rate': 2.5609756097560977e-06, 'epoch': 4.611908467346821}\n",
            "{'eval_loss': 2.2776732444763184, 'eval_rouge1': 0.3806373969898417, 'eval_rouge2': 0.23938542202969126, 'eval_rougeL': 0.33497131378493006, 'eval_rougeLsum': 0.33555611861295, 'eval_runtime': 18.9983, 'eval_samples_per_second': 1.053, 'eval_steps_per_second': 0.263, 'epoch': 4.611908467346821}\n",
            "{'loss': 2.4197, 'grad_norm': 8.680694580078125, 'learning_rate': 2.408536585365854e-06, 'epoch': 4.634964551270967}\n",
            "{'loss': 2.4375, 'grad_norm': 10.314810752868652, 'learning_rate': 2.25609756097561e-06, 'epoch': 4.658020635195112}\n",
            "{'loss': 2.3788, 'grad_norm': 10.446786880493164, 'learning_rate': 2.103658536585366e-06, 'epoch': 4.6810767191192575}\n",
            "{'loss': 2.405, 'grad_norm': 9.397456169128418, 'learning_rate': 1.951219512195122e-06, 'epoch': 4.704132803043403}\n",
            "{'loss': 2.4061, 'grad_norm': 9.964266777038574, 'learning_rate': 1.7987804878048781e-06, 'epoch': 4.727188886967548}\n",
            "{'loss': 2.4322, 'grad_norm': 10.585006713867188, 'learning_rate': 1.6463414634146342e-06, 'epoch': 4.7502449708916945}\n",
            "{'loss': 2.3887, 'grad_norm': 11.28364372253418, 'learning_rate': 1.4939024390243904e-06, 'epoch': 4.77330105481584}\n",
            "{'loss': 2.3988, 'grad_norm': 9.288885116577148, 'learning_rate': 1.3414634146341463e-06, 'epoch': 4.796357138739985}\n",
            "{'loss': 2.3826, 'grad_norm': 10.446377754211426, 'learning_rate': 1.1890243902439024e-06, 'epoch': 4.819413222664131}\n",
            "{'loss': 2.4338, 'grad_norm': 9.383787155151367, 'learning_rate': 1.0365853658536586e-06, 'epoch': 4.842469306588276}\n",
            "{'eval_loss': 2.277078151702881, 'eval_rouge1': 0.3826433934544623, 'eval_rouge2': 0.24462022641671638, 'eval_rougeL': 0.3422076639299248, 'eval_rougeLsum': 0.3428772780911252, 'eval_runtime': 18.7731, 'eval_samples_per_second': 1.065, 'eval_steps_per_second': 0.266, 'epoch': 4.842469306588276}\n",
            "{'loss': 2.4046, 'grad_norm': 10.746038436889648, 'learning_rate': 8.841463414634147e-07, 'epoch': 4.865525390512421}\n",
            "{'loss': 2.4104, 'grad_norm': 10.132163047790527, 'learning_rate': 7.317073170731708e-07, 'epoch': 4.888581474436567}\n",
            "{'loss': 2.3793, 'grad_norm': 9.099323272705078, 'learning_rate': 5.792682926829268e-07, 'epoch': 4.911637558360712}\n",
            "{'loss': 2.4238, 'grad_norm': 9.668848991394043, 'learning_rate': 4.2682926829268293e-07, 'epoch': 4.9346936422848575}\n",
            "{'loss': 2.4165, 'grad_norm': 10.850341796875, 'learning_rate': 2.74390243902439e-07, 'epoch': 4.957749726209004}\n",
            "{'loss': 2.3968, 'grad_norm': 9.030694961547852, 'learning_rate': 1.2195121951219514e-07, 'epoch': 4.980805810133149}\n",
            "{'train_runtime': 43452.6706, 'train_samples_per_second': 15.97, 'train_steps_per_second': 0.249, 'train_loss': 3.2928555238730794, 'epoch': 4.999250677272466}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10840, training_loss=3.2928555238730794, metrics={'train_runtime': 43452.6706, 'train_samples_per_second': 15.97, 'train_steps_per_second': 0.249, 'train_loss': 3.2928555238730794, 'epoch': 4.999250677272466})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=metrics_func,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"].select(range(20)),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EÄŸitilen modeli kaydet\n",
        "output_dir = \"./trained_model\"  # Kaydedilecek dizin\n",
        "trainer.save_model(output_dir)  # Modeli ve tokenizer'Ä± kaydeder\n",
        "\n",
        "# Tokenizer'Ä± ayrÄ±ca kaydetmek isterseniz\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model ve tokenizer {output_dir} dizinine kaydedildi.\")"
      ],
      "metadata": {
        "id": "1yY9QcafhjpV",
        "outputId": "0d16c119-ac67-4426-c922-5944b250c319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ve tokenizer ./trained_model dizinine kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# EÄŸitilen modeli ve tokenizer'Ä± yÃ¼kle\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"./trained_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")\n"
      ],
      "metadata": {
        "id": "piGBJOV-ibHw",
        "outputId": "78a003bf-4297-4542-a8ad-94bdf7310fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"DÃ¼nyamÄ±zda 1900â€™lÃ¼ yÄ±llardan gÃ¼nÃ¼mÃ¼ze kadar dil Ã¶ÄŸretiminde Ã§eÅŸitli metinler kullanÄ±lmÄ±ÅŸtÄ±r. Bunlar â€œ edebi metinler, Ã¼retilmiÅŸ metinler, Ã¶zgÃ¼n ve Ã¶zel metinler â€ baÅŸlÄ±klarÄ± altÄ±nda toplanmÄ±ÅŸtÄ±r. Metinlerin seÃ§imi dil Ã¶ÄŸretim yaklaÅŸÄ±m ve yÃ¶ntemlerine gÃ¶re deÄŸiÅŸmektedir. Her yaklaÅŸÄ±m kendine Ã¶zgÃ¼ metin kullanmÄ±ÅŸtÄ±r. Geleneksel yaklaÅŸÄ±mda dil bilgisi kurallarÄ±, atasÃ¶zleri, edebiyat, genel kÃ¼ltÃ¼r gibi konularÄ±n Ã¶ÄŸretimine aÄŸÄ±rlÄ±k verildiÄŸinden edebi metinler kullanÄ±lmÄ±ÅŸtÄ±r. DavranÄ±ÅŸÃ§Ä± yaklaÅŸÄ±mda dil davranÄ±ÅŸ olarak ele alÄ±nmÄ±ÅŸ, tekrar, taklit ve ezberleme yoluyla Ã¶ÄŸretilmiÅŸtir. Bu yaklaÅŸÄ±mda edebi metinler yerine Ã¼retilmiÅŸ metinler kullanÄ±lmÄ±ÅŸtÄ±r. BiliÅŸsel yaklaÅŸÄ±mda â€œdil iletiÅŸim aracÄ±dÄ±râ€ gÃ¶rÃ¼ÅŸÃ¼ yayÄ±lmÄ±ÅŸ ve Ã¶zgÃ¼n metinler kullanÄ±lmaya baÅŸlanmÄ±ÅŸtÄ±r. \"\n"
      ],
      "metadata": {
        "id": "VKEEh23hislk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    test_text,\n",
        "    return_tensors=\"pt\",  # PyTorch tensÃ¶rleri olarak dÃ¶ner\n",
        "    max_length=1024,      # Modelin giriÅŸ sÄ±nÄ±rÄ±\n",
        "    truncation=True       # Ã‡ok uzun metinleri keser\n",
        ")\n"
      ],
      "metadata": {
        "id": "P0vpkXDdimu6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–zetleme\n",
        "output_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_length=128,  # Ã–zet uzunluÄŸu sÄ±nÄ±rÄ±\n",
        "    num_beams=4,     # Beam search kullanÄ±mÄ±\n",
        "    no_repeat_ngram_size=2,  # Tekrar eden n-gramlarÄ± engeller\n",
        "    length_penalty=0.6       # KÄ±sa Ã¶zetlere Ã¶ncelik\n",
        ")\n",
        "\n",
        "# Ã–zet Ã§Ã¶zÃ¼mleme\n",
        "summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(\"Ã–zet:\", summary)\n"
      ],
      "metadata": {
        "id": "RNB0YFddixHG",
        "outputId": "d2c728ba-c948-426d-f700-0e80b3b76898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ã–zet: DÃ¼nyamÄ±zda 1900â€™lÃ¼ yÄ±llardan gÃ¼nÃ¼mÃ¼ze kadar dil Ã¶ÄŸretiminde Ã§eÅŸitli metinler kullanÄ±lmÄ±ÅŸtÄ±r.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aSDoLGHwj3E9",
        "outputId": "fc0111cb-b972-4a68-900f-49bb63ac221b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}