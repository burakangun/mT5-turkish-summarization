{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ekY1xSZaPV6x"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import TFMT5ForConditionalGeneration, MT5Tokenizer, DataCollatorForSeq2Seq\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sq8j-TtSJNL",
        "outputId": "4cf63a54-477d-4f69-e8b3-b6f1432e601c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "AnCFjnROPV6z"
      },
      "outputs": [],
      "source": [
        "tokenizer = MT5Tokenizer.from_pretrained(\"google/mt5-small\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5pNjX-tPV61",
        "outputId": "4c62c768-5b1a-412e-c70d-27570aafcbca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 138786\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 14610\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['abstract', 'author', 'content', 'date', 'source', 'tags', 'title', 'topic', 'url'],\n",
            "        num_rows: 15379\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "import pandas as pd\n",
        "\n",
        "# Hugging Face'ten veri setini yükleme\n",
        "dataset = load_dataset(\"batubayk/TR-News\")  # Kendi veri setinizin adını yazın\n",
        "\n",
        "# Train ve validation setlerini alın\n",
        "train_dataset = dataset['train']\n",
        "val_dataset = dataset['validation']\n",
        "test_dataset = dataset['test']\n",
        "# Train dataset'in yarısını alma\n",
        "train_half = train_dataset.select(range(len(train_dataset) // 2))\n",
        "\n",
        "\n",
        "# Tüm veri setlerini bir DatasetDict'e dönüştürme\n",
        "combined_datasets = DatasetDict({\n",
        "    'train': train_half,       # Yarıya indirgenmiş train set\n",
        "    'validation': val_dataset, # Validation set\n",
        "    'test': test_dataset       # Test set\n",
        "})\n",
        "\n",
        "# Birleştirilmiş veri setini görüntüleme\n",
        "print(combined_datasets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ympBvHoxPV64",
        "outputId": "16ea2cd0-a8b2-4f8c-f4b3-b4b7d9f1de66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 138786\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 14610\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 15379\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "def tokenize_sample_data(data):\n",
        "\n",
        "    input_feature = tokenizer(data['content'], truncation=True, max_length=1024)\n",
        "    label = tokenizer(data['abstract'], truncation=True, max_length=128)\n",
        "    return {\n",
        "        \"input_ids\" : input_feature['input_ids'],\n",
        "        \"attention_mask\" : input_feature['attention_mask'],\n",
        "        \"labels\" : label['input_ids'],\n",
        "    }\n",
        "\n",
        "tokenized_ds = combined_datasets.map(\n",
        "    tokenize_sample_data,\n",
        "    remove_columns= ['abstract','author','content','date','source','tags','title','topic','url'],\n",
        "    batched=True,\n",
        "    batch_size= 512\n",
        ")\n",
        "tokenized_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "hQwKEJ42PV65",
        "outputId": "2bc1c13d-2a84-44fc-f1b5-cd570fea74d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nfrom transformers import MT5Tokenizer, MT5ForConditionalGeneration\\n\\n# 1. Tokenizer ve modelin yüklenmesi\\nmodel_name = \"google/mt5-small\"\\ntokenizer = MT5Tokenizer.from_pretrained(model_name)\\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)\\n\\n# 2. Özetlenmek istenen Türkçe metin\\nturkish_text = \"\"\"\\nİklim değişikliği, küresel sıcaklıkların artışıyla birlikte ortaya çıkan çevresel, sosyal ve ekonomik sorunlara neden olmaktadır.\\nÖzellikle kuraklık, sel ve orman yangınları gibi doğal afetlerin sıklığı artarken, tarımsal üretimde de ciddi düşüşler yaşanmaktadır.\\nBu durum, gıda güvenliğini tehdit etmekte ve toplumları olumsuz yönde etkilemektedir.\\n\"\"\"\\n\\n# 3. Özetleme için giriş formatı: \\'summarize:\\' ön ekini ekliyoruz\\ninput_text = f\"summarize: {turkish_text}\"\\n\\n# 4. Tokenizer ile metni encode etme\\ninput_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\\n\\n# 5. Modeli kullanarak özetleme yapma\\nsummary_ids = model.generate(\\n    input_ids, \\n    max_length=150, \\n    min_length=30, \\n    length_penalty=2.0, \\n    num_beams=4, \\n    early_stopping=True\\n)\\n\\n# 6. Özetlenen metni decode etme\\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\\n\\n# 7. Sonucu yazdırma\\nprint(\"Özetlenen Metin:\")\\nprint(summary)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "from transformers import MT5Tokenizer, MT5ForConditionalGeneration\n",
        "\n",
        "# 1. Tokenizer ve modelin yüklenmesi\n",
        "model_name = \"google/mt5-small\"\n",
        "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
        "model = MT5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# 2. Özetlenmek istenen Türkçe metin\n",
        "turkish_text = \"\"\"\n",
        "İklim değişikliği, küresel sıcaklıkların artışıyla birlikte ortaya çıkan çevresel, sosyal ve ekonomik sorunlara neden olmaktadır.\n",
        "Özellikle kuraklık, sel ve orman yangınları gibi doğal afetlerin sıklığı artarken, tarımsal üretimde de ciddi düşüşler yaşanmaktadır.\n",
        "Bu durum, gıda güvenliğini tehdit etmekte ve toplumları olumsuz yönde etkilemektedir.\n",
        "\"\"\"\n",
        "\n",
        "# 3. Özetleme için giriş formatı: 'summarize:' ön ekini ekliyoruz\n",
        "input_text = f\"summarize: {turkish_text}\"\n",
        "\n",
        "# 4. Tokenizer ile metni encode etme\n",
        "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
        "\n",
        "# 5. Modeli kullanarak özetleme yapma\n",
        "summary_ids = model.generate(\n",
        "    input_ids,\n",
        "    max_length=150,\n",
        "    min_length=30,\n",
        "    length_penalty=2.0,\n",
        "    num_beams=4,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# 6. Özetlenen metni decode etme\n",
        "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "# 7. Sonucu yazdırma\n",
        "print(\"Özetlenen Metin:\")\n",
        "print(summary)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Kvsu1jtiPV66"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoConfig, AutoModelForSeq2SeqLM\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model konfigürasyonu\n",
        "mt5_config = AutoConfig.from_pretrained(\n",
        "    \"google/mt5-small\",\n",
        "    max_length=128,\n",
        "    length_penalty=0.6,\n",
        "    no_repeat_ngram_size=2,\n",
        "    num_beams=15,\n",
        ")\n",
        "\n",
        "# PyTorch tabanlı modeli yükleme ve GPU/CPU'ya taşıma\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/mt5-small\", config=mt5_config).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "kL7j5kNqPV67"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(\n",
        "  tokenizer,\n",
        "  model=model,\n",
        "  return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "o9p6BzTgPV67"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# define function for custom tokenization\n",
        "def tokenize_sentence(arg):\n",
        "  encoded_arg = tokenizer(arg)\n",
        "  return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
        "\n",
        "# define function to get ROUGE scores with custom tokenization\n",
        "def metrics_func(eval_arg):\n",
        "  preds, labels = eval_arg\n",
        "  # Replace -100\n",
        "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "  # Convert id tokens to text\n",
        "  text_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "  text_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "  # Insert a line break (\\n) in each sentence for ROUGE scoring\n",
        "  # (Note : Please change this code, when you perform on other languages except for Japanese)\n",
        "  text_preds = [(p if p.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else p + \"。\") for p in text_preds]\n",
        "  text_labels = [(l if l.endswith((\"!\", \"！\", \"?\", \"？\", \"。\")) else l + \"。\") for l in text_labels]\n",
        "  sent_tokenizer_jp = RegexpTokenizer(u'[^!！?？。]*[!！?？。]')\n",
        "  text_preds = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(p))) for p in text_preds]\n",
        "  text_labels = [\"\\n\".join(np.char.strip(sent_tokenizer_jp.tokenize(l))) for l in text_labels]\n",
        "  # compute ROUGE score with custom tokenization\n",
        "  return rouge_metric.compute(\n",
        "    predictions=text_preds,\n",
        "    references=text_labels,\n",
        "    tokenizer=tokenize_sentence\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED_Q-uAc16eV",
        "outputId": "b6b26a49-0a7e-43ce-d38e-ea684b80b8b4"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "508khiopPV67",
        "outputId": "b4937020-38fe-448f-f67d-eb8a348b5a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"mt5-summarize-ja\",\n",
        "    log_level=\"error\",\n",
        "    num_train_epochs=5,  # Eğitim süresini kısaltmak gerekebilir\n",
        "    learning_rate=3e-5,  # Daha düşük öğrenme oranı, büyük veri setlerinde genellikle daha iyidir\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_steps=1000,  # Daha fazla warmup adımı, büyük veri setleri için faydalı olabilir\n",
        "    optim=\"adafactor\",\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=8,  # Batch boyutunu artırmak daha iyi sonuç verebilir\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,  # Büyük bir batch boyutu elde etmek için gradient accumulation kullanımı\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,  # Değerlendirme adımlarını artırma\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=128,\n",
        "    save_steps=1000,  # Daha sık model kaydetme\n",
        "    logging_steps=50,  # Daha az sık loglama\n",
        "    push_to_hub=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GdDg8SNEPV68",
        "outputId": "a702983b-883b-4942-f042-1261efcf706a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241204_182935-u8gw9xm3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3' target=\"_blank\">mt5-summarize-ja</a></strong> to <a href='https://wandb.ai/buraak380-balikesir-university/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/buraak380-balikesir-university/huggingface' target=\"_blank\">https://wandb.ai/buraak380-balikesir-university/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3' target=\"_blank\">https://wandb.ai/buraak380-balikesir-university/huggingface/runs/u8gw9xm3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 24.5112, 'grad_norm': 16774.7421875, 'learning_rate': 1.5e-06, 'epoch': 0.023056083924145484}\n",
            "{'loss': 23.6268, 'grad_norm': 7427.5166015625, 'learning_rate': 3e-06, 'epoch': 0.04611216784829097}\n",
            "{'loss': 22.1511, 'grad_norm': 11378.0224609375, 'learning_rate': 4.5e-06, 'epoch': 0.06916825177243645}\n",
            "{'loss': 20.1197, 'grad_norm': 19247.185546875, 'learning_rate': 6e-06, 'epoch': 0.09222433569658194}\n",
            "{'loss': 17.8633, 'grad_norm': 14236.763671875, 'learning_rate': 7.5e-06, 'epoch': 0.11528041962072742}\n",
            "{'loss': 15.1001, 'grad_norm': 3186.00537109375, 'learning_rate': 9e-06, 'epoch': 0.1383365035448729}\n",
            "{'loss': 12.5646, 'grad_norm': 2478.00537109375, 'learning_rate': 1.05e-05, 'epoch': 0.16139258746901838}\n",
            "{'loss': 10.0196, 'grad_norm': 1175.4456787109375, 'learning_rate': 1.2e-05, 'epoch': 0.18444867139316387}\n",
            "{'loss': 7.8663, 'grad_norm': 529.7356567382812, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.20750475531730936}\n",
            "{'loss': 6.6431, 'grad_norm': 198.30833435058594, 'learning_rate': 1.5e-05, 'epoch': 0.23056083924145485}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1493: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 3.2425925731658936, 'eval_rouge1': 0.27868188998239907, 'eval_rouge2': 0.1480487905727444, 'eval_rougeL': 0.21579057046004535, 'eval_rougeLsum': 0.21626552718006642, 'eval_runtime': 33.5535, 'eval_samples_per_second': 0.596, 'eval_steps_per_second': 0.149, 'epoch': 0.23056083924145485}\n",
            "{'loss': 5.8539, 'grad_norm': 146.40818786621094, 'learning_rate': 1.65e-05, 'epoch': 0.2536169231656003}\n",
            "{'loss': 5.1889, 'grad_norm': 111.25946044921875, 'learning_rate': 1.8e-05, 'epoch': 0.2766730070897458}\n",
            "{'loss': 4.7205, 'grad_norm': 1226.7098388671875, 'learning_rate': 1.95e-05, 'epoch': 0.2997290910138913}\n",
            "{'loss': 4.4035, 'grad_norm': 27.96617317199707, 'learning_rate': 2.1e-05, 'epoch': 0.32278517493803677}\n",
            "{'loss': 4.227, 'grad_norm': 98.8541259765625, 'learning_rate': 2.25e-05, 'epoch': 0.34584125886218225}\n",
            "{'loss': 3.9979, 'grad_norm': 18.958141326904297, 'learning_rate': 2.4e-05, 'epoch': 0.36889734278632774}\n",
            "{'loss': 3.901, 'grad_norm': 17.45825958251953, 'learning_rate': 2.55e-05, 'epoch': 0.39195342671047323}\n",
            "{'loss': 3.7696, 'grad_norm': 19.302753448486328, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.4150095106346187}\n",
            "{'loss': 3.723, 'grad_norm': 15.533737182617188, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.4380655945587642}\n",
            "{'loss': 3.6061, 'grad_norm': 16.410594940185547, 'learning_rate': 3e-05, 'epoch': 0.4611216784829097}\n",
            "{'eval_loss': 2.9723572731018066, 'eval_rouge1': 0.30271807882962576, 'eval_rouge2': 0.1758935949790496, 'eval_rougeL': 0.2721390309032612, 'eval_rougeLsum': 0.27298056001547855, 'eval_runtime': 13.904, 'eval_samples_per_second': 1.438, 'eval_steps_per_second': 0.36, 'epoch': 0.4611216784829097}\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 128, 'num_beams': 15, 'length_penalty': 0.6, 'no_repeat_ngram_size': 2}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.5721, 'grad_norm': 17.894153594970703, 'learning_rate': 2.9847560975609756e-05, 'epoch': 0.4841777624070552}\n",
            "{'loss': 3.5084, 'grad_norm': 16.740772247314453, 'learning_rate': 2.9695121951219515e-05, 'epoch': 0.5072338463312006}\n",
            "{'loss': 3.4453, 'grad_norm': 14.236841201782227, 'learning_rate': 2.954268292682927e-05, 'epoch': 0.5302899302553461}\n",
            "{'loss': 3.3784, 'grad_norm': 14.119400978088379, 'learning_rate': 2.9390243902439022e-05, 'epoch': 0.5533460141794916}\n",
            "{'loss': 3.3471, 'grad_norm': 14.839422225952148, 'learning_rate': 2.923780487804878e-05, 'epoch': 0.5764020981036371}\n",
            "{'loss': 3.3048, 'grad_norm': 18.75555992126465, 'learning_rate': 2.9085365853658536e-05, 'epoch': 0.5994581820277826}\n",
            "{'loss': 3.2665, 'grad_norm': 14.308640480041504, 'learning_rate': 2.8932926829268295e-05, 'epoch': 0.622514265951928}\n",
            "{'loss': 3.191, 'grad_norm': 12.731827735900879, 'learning_rate': 2.878048780487805e-05, 'epoch': 0.6455703498760735}\n",
            "{'loss': 3.1721, 'grad_norm': 12.812121391296387, 'learning_rate': 2.8628048780487805e-05, 'epoch': 0.668626433800219}\n",
            "{'loss': 3.1435, 'grad_norm': 11.910759925842285, 'learning_rate': 2.8475609756097564e-05, 'epoch': 0.6916825177243645}\n",
            "{'eval_loss': 2.671978235244751, 'eval_rouge1': 0.37050786927389445, 'eval_rouge2': 0.2286977597882208, 'eval_rougeL': 0.3337544872995933, 'eval_rougeLsum': 0.3346952790445227, 'eval_runtime': 15.0581, 'eval_samples_per_second': 1.328, 'eval_steps_per_second': 0.332, 'epoch': 0.6916825177243645}\n",
            "{'loss': 3.1082, 'grad_norm': 13.50170612335205, 'learning_rate': 2.832317073170732e-05, 'epoch': 0.71473860164851}\n",
            "{'loss': 3.072, 'grad_norm': 14.895974159240723, 'learning_rate': 2.817073170731707e-05, 'epoch': 0.7377946855726555}\n",
            "{'loss': 3.0587, 'grad_norm': 13.28650188446045, 'learning_rate': 2.801829268292683e-05, 'epoch': 0.760850769496801}\n",
            "{'loss': 3.0329, 'grad_norm': 26.724464416503906, 'learning_rate': 2.7865853658536585e-05, 'epoch': 0.7839068534209465}\n",
            "{'loss': 3.0199, 'grad_norm': 11.835593223571777, 'learning_rate': 2.7713414634146344e-05, 'epoch': 0.806962937345092}\n",
            "{'loss': 2.9894, 'grad_norm': 13.087066650390625, 'learning_rate': 2.75609756097561e-05, 'epoch': 0.8300190212692374}\n",
            "{'loss': 2.9879, 'grad_norm': 12.32600212097168, 'learning_rate': 2.7408536585365854e-05, 'epoch': 0.8530751051933829}\n",
            "{'loss': 2.9778, 'grad_norm': 11.856870651245117, 'learning_rate': 2.7256097560975613e-05, 'epoch': 0.8761311891175284}\n",
            "{'loss': 2.9662, 'grad_norm': 14.248811721801758, 'learning_rate': 2.7103658536585365e-05, 'epoch': 0.8991872730416739}\n",
            "{'loss': 2.9001, 'grad_norm': 15.733882904052734, 'learning_rate': 2.695121951219512e-05, 'epoch': 0.9222433569658194}\n",
            "{'eval_loss': 2.5733323097229004, 'eval_rouge1': 0.39693081747804754, 'eval_rouge2': 0.25594390684733925, 'eval_rougeL': 0.35755217057451005, 'eval_rougeLsum': 0.358118159391117, 'eval_runtime': 16.9776, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 0.295, 'epoch': 0.9222433569658194}\n",
            "{'loss': 2.9093, 'grad_norm': 12.118583679199219, 'learning_rate': 2.679878048780488e-05, 'epoch': 0.9452994408899649}\n",
            "{'loss': 2.8922, 'grad_norm': 11.997276306152344, 'learning_rate': 2.6646341463414634e-05, 'epoch': 0.9683555248141104}\n",
            "{'loss': 2.8862, 'grad_norm': 12.037343978881836, 'learning_rate': 2.6493902439024393e-05, 'epoch': 0.9914116087382558}\n",
            "{'loss': 2.9021, 'grad_norm': 30.4051570892334, 'learning_rate': 2.6341463414634148e-05, 'epoch': 1.0146406132918324}\n",
            "{'loss': 2.8793, 'grad_norm': 12.55605697631836, 'learning_rate': 2.6189024390243903e-05, 'epoch': 1.0376966972159778}\n",
            "{'loss': 2.8192, 'grad_norm': 12.40013313293457, 'learning_rate': 2.603658536585366e-05, 'epoch': 1.0607527811401234}\n",
            "{'loss': 2.7986, 'grad_norm': 12.453566551208496, 'learning_rate': 2.5884146341463414e-05, 'epoch': 1.0838088650642688}\n",
            "{'loss': 2.7801, 'grad_norm': 12.573058128356934, 'learning_rate': 2.573170731707317e-05, 'epoch': 1.1068649489884144}\n",
            "{'loss': 2.8358, 'grad_norm': 11.075135231018066, 'learning_rate': 2.5579268292682928e-05, 'epoch': 1.1299210329125597}\n",
            "{'loss': 2.82, 'grad_norm': 12.062179565429688, 'learning_rate': 2.5426829268292683e-05, 'epoch': 1.1529771168367053}\n",
            "{'eval_loss': 2.488537311553955, 'eval_rouge1': 0.39003671071858587, 'eval_rouge2': 0.25675818407234635, 'eval_rougeL': 0.3583678841990378, 'eval_rougeLsum': 0.3589805907802068, 'eval_runtime': 17.2468, 'eval_samples_per_second': 1.16, 'eval_steps_per_second': 0.29, 'epoch': 1.1529771168367053}\n",
            "{'loss': 2.8226, 'grad_norm': 10.972772598266602, 'learning_rate': 2.527439024390244e-05, 'epoch': 1.1760332007608507}\n",
            "{'loss': 2.8051, 'grad_norm': 11.943621635437012, 'learning_rate': 2.5121951219512197e-05, 'epoch': 1.1990892846849963}\n",
            "{'loss': 2.7673, 'grad_norm': 12.048783302307129, 'learning_rate': 2.4969512195121952e-05, 'epoch': 1.2221453686091417}\n",
            "{'loss': 2.7717, 'grad_norm': 19.191055297851562, 'learning_rate': 2.4817073170731708e-05, 'epoch': 1.2452014525332873}\n",
            "{'loss': 2.7859, 'grad_norm': 14.062714576721191, 'learning_rate': 2.4664634146341463e-05, 'epoch': 1.2682575364574327}\n",
            "{'loss': 2.741, 'grad_norm': 12.391724586486816, 'learning_rate': 2.4512195121951218e-05, 'epoch': 1.2913136203815783}\n",
            "{'loss': 2.7456, 'grad_norm': 10.558584213256836, 'learning_rate': 2.4359756097560977e-05, 'epoch': 1.3143697043057236}\n",
            "{'loss': 2.7459, 'grad_norm': 10.626717567443848, 'learning_rate': 2.4207317073170732e-05, 'epoch': 1.3374257882298692}\n",
            "{'loss': 2.7152, 'grad_norm': 10.615509033203125, 'learning_rate': 2.405487804878049e-05, 'epoch': 1.3604818721540146}\n",
            "{'loss': 2.7095, 'grad_norm': 10.243266105651855, 'learning_rate': 2.3902439024390246e-05, 'epoch': 1.3835379560781602}\n",
            "{'eval_loss': 2.484046697616577, 'eval_rouge1': 0.37873493416895726, 'eval_rouge2': 0.24486176201486176, 'eval_rougeL': 0.33953489873993603, 'eval_rougeLsum': 0.33928699915835925, 'eval_runtime': 17.6459, 'eval_samples_per_second': 1.133, 'eval_steps_per_second': 0.283, 'epoch': 1.3835379560781602}\n",
            "{'loss': 2.7333, 'grad_norm': 10.008904457092285, 'learning_rate': 2.3749999999999998e-05, 'epoch': 1.4065940400023056}\n",
            "{'loss': 2.7013, 'grad_norm': 11.850410461425781, 'learning_rate': 2.3597560975609757e-05, 'epoch': 1.429650123926451}\n",
            "{'loss': 2.7116, 'grad_norm': 12.326692581176758, 'learning_rate': 2.3445121951219512e-05, 'epoch': 1.4527062078505966}\n",
            "{'loss': 2.7024, 'grad_norm': 9.918496131896973, 'learning_rate': 2.3292682926829267e-05, 'epoch': 1.4757622917747422}\n",
            "{'loss': 2.6715, 'grad_norm': 14.097129821777344, 'learning_rate': 2.3140243902439026e-05, 'epoch': 1.4988183756988875}\n",
            "{'loss': 2.6666, 'grad_norm': 11.665379524230957, 'learning_rate': 2.298780487804878e-05, 'epoch': 1.521874459623033}\n",
            "{'loss': 2.6709, 'grad_norm': 12.764392852783203, 'learning_rate': 2.283536585365854e-05, 'epoch': 1.5449305435471785}\n",
            "{'loss': 2.679, 'grad_norm': 11.160256385803223, 'learning_rate': 2.2682926829268295e-05, 'epoch': 1.5679866274713241}\n",
            "{'loss': 2.6482, 'grad_norm': 9.983196258544922, 'learning_rate': 2.2530487804878047e-05, 'epoch': 1.5910427113954695}\n",
            "{'loss': 2.63, 'grad_norm': 11.062216758728027, 'learning_rate': 2.2378048780487806e-05, 'epoch': 1.6140987953196149}\n",
            "{'eval_loss': 2.4477429389953613, 'eval_rouge1': 0.39323026525434823, 'eval_rouge2': 0.2550425344591487, 'eval_rougeL': 0.35225490694804074, 'eval_rougeLsum': 0.35383491119368793, 'eval_runtime': 18.2138, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 0.275, 'epoch': 1.6140987953196149}\n",
            "{'loss': 2.6592, 'grad_norm': 11.190690994262695, 'learning_rate': 2.222560975609756e-05, 'epoch': 1.6371548792437605}\n",
            "{'loss': 2.6427, 'grad_norm': 12.247944831848145, 'learning_rate': 2.2073170731707316e-05, 'epoch': 1.660210963167906}\n",
            "{'loss': 2.6491, 'grad_norm': 12.402313232421875, 'learning_rate': 2.1920731707317075e-05, 'epoch': 1.6832670470920514}\n",
            "{'loss': 2.6353, 'grad_norm': 11.387008666992188, 'learning_rate': 2.176829268292683e-05, 'epoch': 1.7063231310161968}\n",
            "{'loss': 2.6329, 'grad_norm': 11.37997055053711, 'learning_rate': 2.161585365853659e-05, 'epoch': 1.7293792149403424}\n",
            "{'loss': 2.6225, 'grad_norm': 12.697090148925781, 'learning_rate': 2.146341463414634e-05, 'epoch': 1.752435298864488}\n",
            "{'loss': 2.6273, 'grad_norm': 10.799772262573242, 'learning_rate': 2.1310975609756096e-05, 'epoch': 1.7754913827886334}\n",
            "{'loss': 2.6479, 'grad_norm': 10.632664680480957, 'learning_rate': 2.1158536585365855e-05, 'epoch': 1.7985474667127788}\n",
            "{'loss': 2.6141, 'grad_norm': 10.648881912231445, 'learning_rate': 2.100609756097561e-05, 'epoch': 1.8216035506369244}\n",
            "{'loss': 2.6261, 'grad_norm': 10.205967903137207, 'learning_rate': 2.0853658536585365e-05, 'epoch': 1.84465963456107}\n",
            "{'eval_loss': 2.3877484798431396, 'eval_rouge1': 0.39449659037124907, 'eval_rouge2': 0.25753367282579664, 'eval_rougeL': 0.3537852554455278, 'eval_rougeLsum': 0.3548470875555577, 'eval_runtime': 17.2095, 'eval_samples_per_second': 1.162, 'eval_steps_per_second': 0.291, 'epoch': 1.84465963456107}\n",
            "{'loss': 2.6014, 'grad_norm': 10.895798683166504, 'learning_rate': 2.0701219512195124e-05, 'epoch': 1.8677157184852153}\n",
            "{'loss': 2.5797, 'grad_norm': 10.948487281799316, 'learning_rate': 2.054878048780488e-05, 'epoch': 1.8907718024093607}\n",
            "{'loss': 2.5615, 'grad_norm': 13.712175369262695, 'learning_rate': 2.0396341463414635e-05, 'epoch': 1.913827886333506}\n",
            "{'loss': 2.56, 'grad_norm': 10.63505744934082, 'learning_rate': 2.024390243902439e-05, 'epoch': 1.9368839702576517}\n",
            "{'loss': 2.5922, 'grad_norm': 9.867226600646973, 'learning_rate': 2.0091463414634145e-05, 'epoch': 1.9599400541817973}\n",
            "{'loss': 2.6018, 'grad_norm': 10.09182071685791, 'learning_rate': 1.9939024390243904e-05, 'epoch': 1.9829961381059427}\n",
            "{'loss': 2.5689, 'grad_norm': 12.514313697814941, 'learning_rate': 1.978658536585366e-05, 'epoch': 2.0062251426595195}\n",
            "{'loss': 2.5797, 'grad_norm': 11.642801284790039, 'learning_rate': 1.9634146341463414e-05, 'epoch': 2.029281226583665}\n",
            "{'loss': 2.5515, 'grad_norm': 10.051085472106934, 'learning_rate': 1.9481707317073173e-05, 'epoch': 2.05233731050781}\n",
            "{'loss': 2.5485, 'grad_norm': 12.150893211364746, 'learning_rate': 1.9329268292682928e-05, 'epoch': 2.0753933944319556}\n",
            "{'eval_loss': 2.390402317047119, 'eval_rouge1': 0.4010516806697192, 'eval_rouge2': 0.2606489317924252, 'eval_rougeL': 0.35649923689976215, 'eval_rougeLsum': 0.35725713733756825, 'eval_runtime': 18.4574, 'eval_samples_per_second': 1.084, 'eval_steps_per_second': 0.271, 'epoch': 2.0753933944319556}\n",
            "{'loss': 2.5916, 'grad_norm': 10.23307991027832, 'learning_rate': 1.9176829268292684e-05, 'epoch': 2.0984494783561014}\n",
            "{'loss': 2.5922, 'grad_norm': 10.200557708740234, 'learning_rate': 1.902439024390244e-05, 'epoch': 2.121505562280247}\n",
            "{'loss': 2.5395, 'grad_norm': 11.209213256835938, 'learning_rate': 1.8871951219512194e-05, 'epoch': 2.144561646204392}\n",
            "{'loss': 2.5569, 'grad_norm': 10.434911727905273, 'learning_rate': 1.8719512195121953e-05, 'epoch': 2.1676177301285375}\n",
            "{'loss': 2.5531, 'grad_norm': 10.402155876159668, 'learning_rate': 1.8567073170731708e-05, 'epoch': 2.1906738140526834}\n",
            "{'loss': 2.5613, 'grad_norm': 12.685647964477539, 'learning_rate': 1.8414634146341463e-05, 'epoch': 2.2137298979768287}\n",
            "{'loss': 2.5418, 'grad_norm': 11.835286140441895, 'learning_rate': 1.8262195121951222e-05, 'epoch': 2.236785981900974}\n",
            "{'loss': 2.5361, 'grad_norm': 14.57607364654541, 'learning_rate': 1.8109756097560974e-05, 'epoch': 2.2598420658251195}\n",
            "{'loss': 2.5637, 'grad_norm': 9.632112503051758, 'learning_rate': 1.7957317073170733e-05, 'epoch': 2.282898149749265}\n",
            "{'loss': 2.524, 'grad_norm': 10.669240951538086, 'learning_rate': 1.7804878048780488e-05, 'epoch': 2.3059542336734107}\n",
            "{'eval_loss': 2.3560826778411865, 'eval_rouge1': 0.3992679171477902, 'eval_rouge2': 0.2575042612949556, 'eval_rougeL': 0.35454723314978964, 'eval_rougeLsum': 0.3552318329911385, 'eval_runtime': 18.5737, 'eval_samples_per_second': 1.077, 'eval_steps_per_second': 0.269, 'epoch': 2.3059542336734107}\n",
            "{'loss': 2.5353, 'grad_norm': 10.125628471374512, 'learning_rate': 1.7652439024390243e-05, 'epoch': 2.329010317597556}\n",
            "{'loss': 2.5441, 'grad_norm': 10.290915489196777, 'learning_rate': 1.7500000000000002e-05, 'epoch': 2.3520664015217014}\n",
            "{'loss': 2.5743, 'grad_norm': 9.975162506103516, 'learning_rate': 1.7347560975609757e-05, 'epoch': 2.3751224854458473}\n",
            "{'loss': 2.5028, 'grad_norm': 10.689591407775879, 'learning_rate': 1.7195121951219512e-05, 'epoch': 2.3981785693699926}\n",
            "{'loss': 2.5274, 'grad_norm': 10.335311889648438, 'learning_rate': 1.704268292682927e-05, 'epoch': 2.421234653294138}\n",
            "{'loss': 2.484, 'grad_norm': 10.17721176147461, 'learning_rate': 1.6890243902439023e-05, 'epoch': 2.4442907372182834}\n",
            "{'loss': 2.5069, 'grad_norm': 10.193964004516602, 'learning_rate': 1.673780487804878e-05, 'epoch': 2.4673468211424288}\n",
            "{'loss': 2.528, 'grad_norm': 10.874619483947754, 'learning_rate': 1.6585365853658537e-05, 'epoch': 2.4904029050665746}\n",
            "{'loss': 2.5267, 'grad_norm': 10.26282024383545, 'learning_rate': 1.6432926829268292e-05, 'epoch': 2.51345898899072}\n",
            "{'loss': 2.5143, 'grad_norm': 14.831817626953125, 'learning_rate': 1.628048780487805e-05, 'epoch': 2.5365150729148653}\n",
            "{'eval_loss': 2.341432571411133, 'eval_rouge1': 0.39974184941599744, 'eval_rouge2': 0.26026352958285737, 'eval_rougeL': 0.35623961335591436, 'eval_rougeLsum': 0.3564560787247349, 'eval_runtime': 18.2298, 'eval_samples_per_second': 1.097, 'eval_steps_per_second': 0.274, 'epoch': 2.5365150729148653}\n",
            "{'loss': 2.507, 'grad_norm': 10.934913635253906, 'learning_rate': 1.6128048780487806e-05, 'epoch': 2.559571156839011}\n",
            "{'loss': 2.4973, 'grad_norm': 9.496092796325684, 'learning_rate': 1.597560975609756e-05, 'epoch': 2.5826272407631565}\n",
            "{'loss': 2.5138, 'grad_norm': 11.387688636779785, 'learning_rate': 1.5823170731707317e-05, 'epoch': 2.605683324687302}\n",
            "{'loss': 2.5045, 'grad_norm': 10.355055809020996, 'learning_rate': 1.5670731707317072e-05, 'epoch': 2.6287394086114473}\n",
            "{'loss': 2.5228, 'grad_norm': 11.655776977539062, 'learning_rate': 1.551829268292683e-05, 'epoch': 2.6517954925355927}\n",
            "{'loss': 2.5229, 'grad_norm': 53.177574157714844, 'learning_rate': 1.5365853658536586e-05, 'epoch': 2.6748515764597385}\n",
            "{'loss': 2.4785, 'grad_norm': 10.859707832336426, 'learning_rate': 1.5213414634146341e-05, 'epoch': 2.697907660383884}\n",
            "{'loss': 2.4968, 'grad_norm': 9.2811918258667, 'learning_rate': 1.5060975609756098e-05, 'epoch': 2.7209637443080292}\n",
            "{'loss': 2.4839, 'grad_norm': 10.754032135009766, 'learning_rate': 1.4908536585365854e-05, 'epoch': 2.7440198282321746}\n",
            "{'loss': 2.5342, 'grad_norm': 10.507895469665527, 'learning_rate': 1.475609756097561e-05, 'epoch': 2.7670759121563204}\n",
            "{'eval_loss': 2.3251986503601074, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 18.5867, 'eval_samples_per_second': 1.076, 'eval_steps_per_second': 0.269, 'epoch': 2.7670759121563204}\n",
            "{'loss': 2.4711, 'grad_norm': 10.149398803710938, 'learning_rate': 1.4603658536585368e-05, 'epoch': 2.790131996080466}\n",
            "{'loss': 2.4846, 'grad_norm': 10.495892524719238, 'learning_rate': 1.4451219512195121e-05, 'epoch': 2.813188080004611}\n",
            "{'loss': 2.4918, 'grad_norm': 10.914058685302734, 'learning_rate': 1.4298780487804878e-05, 'epoch': 2.8362441639287566}\n",
            "{'loss': 2.4887, 'grad_norm': 9.305901527404785, 'learning_rate': 1.4146341463414635e-05, 'epoch': 2.859300247852902}\n",
            "{'loss': 2.4765, 'grad_norm': 10.311554908752441, 'learning_rate': 1.3993902439024392e-05, 'epoch': 2.8823563317770478}\n",
            "{'loss': 2.4838, 'grad_norm': 9.935501098632812, 'learning_rate': 1.3841463414634146e-05, 'epoch': 2.905412415701193}\n",
            "{'loss': 2.4697, 'grad_norm': 9.06320571899414, 'learning_rate': 1.3689024390243903e-05, 'epoch': 2.9284684996253385}\n",
            "{'loss': 2.4991, 'grad_norm': 10.720715522766113, 'learning_rate': 1.353658536585366e-05, 'epoch': 2.9515245835494843}\n",
            "{'loss': 2.4778, 'grad_norm': 9.226786613464355, 'learning_rate': 1.3384146341463417e-05, 'epoch': 2.9745806674736297}\n",
            "{'loss': 2.4855, 'grad_norm': 9.26325798034668, 'learning_rate': 1.323170731707317e-05, 'epoch': 2.997636751397775}\n",
            "{'eval_loss': 2.3187615871429443, 'eval_rouge1': 0.3826433934544623, 'eval_rouge2': 0.24462022641671638, 'eval_rougeL': 0.3422076639299248, 'eval_rougeLsum': 0.3428772780911252, 'eval_runtime': 19.3079, 'eval_samples_per_second': 1.036, 'eval_steps_per_second': 0.259, 'epoch': 2.997636751397775}\n",
            "{'loss': 2.4724, 'grad_norm': 10.1837797164917, 'learning_rate': 1.3079268292682927e-05, 'epoch': 3.020865755951352}\n",
            "{'loss': 2.4389, 'grad_norm': 9.090506553649902, 'learning_rate': 1.2926829268292684e-05, 'epoch': 3.0439218398754972}\n",
            "{'loss': 2.4994, 'grad_norm': 10.189800262451172, 'learning_rate': 1.277439024390244e-05, 'epoch': 3.0669779237996426}\n",
            "{'loss': 2.4831, 'grad_norm': 10.558107376098633, 'learning_rate': 1.2621951219512195e-05, 'epoch': 3.090034007723788}\n",
            "{'loss': 2.4505, 'grad_norm': 11.447772979736328, 'learning_rate': 1.2469512195121952e-05, 'epoch': 3.1130900916479334}\n",
            "{'loss': 2.4395, 'grad_norm': 11.130088806152344, 'learning_rate': 1.2317073170731709e-05, 'epoch': 3.136146175572079}\n",
            "{'loss': 2.441, 'grad_norm': 12.401923179626465, 'learning_rate': 1.2164634146341464e-05, 'epoch': 3.1592022594962246}\n",
            "{'loss': 2.4468, 'grad_norm': 26.60920524597168, 'learning_rate': 1.201219512195122e-05, 'epoch': 3.18225834342037}\n",
            "{'loss': 2.4667, 'grad_norm': 9.639086723327637, 'learning_rate': 1.1859756097560976e-05, 'epoch': 3.2053144273445153}\n",
            "{'loss': 2.4637, 'grad_norm': 9.803449630737305, 'learning_rate': 1.1707317073170733e-05, 'epoch': 3.228370511268661}\n",
            "{'eval_loss': 2.2940685749053955, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 17.6361, 'eval_samples_per_second': 1.134, 'eval_steps_per_second': 0.284, 'epoch': 3.228370511268661}\n",
            "{'loss': 2.4859, 'grad_norm': 10.089349746704102, 'learning_rate': 1.1554878048780488e-05, 'epoch': 3.2514265951928065}\n",
            "{'loss': 2.5076, 'grad_norm': 9.369735717773438, 'learning_rate': 1.1402439024390244e-05, 'epoch': 3.274482679116952}\n",
            "{'loss': 2.4329, 'grad_norm': 11.167649269104004, 'learning_rate': 1.125e-05, 'epoch': 3.2975387630410973}\n",
            "{'loss': 2.4434, 'grad_norm': 9.39116096496582, 'learning_rate': 1.1097560975609756e-05, 'epoch': 3.320594846965243}\n",
            "{'loss': 2.4462, 'grad_norm': 10.141561508178711, 'learning_rate': 1.0945121951219511e-05, 'epoch': 3.3436509308893885}\n",
            "{'loss': 2.467, 'grad_norm': 10.090742111206055, 'learning_rate': 1.0792682926829268e-05, 'epoch': 3.366707014813534}\n",
            "{'loss': 2.4683, 'grad_norm': 10.877820014953613, 'learning_rate': 1.0640243902439025e-05, 'epoch': 3.3897630987376792}\n",
            "{'loss': 2.431, 'grad_norm': 10.741387367248535, 'learning_rate': 1.048780487804878e-05, 'epoch': 3.412819182661825}\n",
            "{'loss': 2.4201, 'grad_norm': 10.327797889709473, 'learning_rate': 1.0335365853658536e-05, 'epoch': 3.4358752665859704}\n",
            "{'loss': 2.4598, 'grad_norm': 9.451332092285156, 'learning_rate': 1.0182926829268293e-05, 'epoch': 3.458931350510116}\n",
            "{'eval_loss': 2.3005118370056152, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 19.163, 'eval_samples_per_second': 1.044, 'eval_steps_per_second': 0.261, 'epoch': 3.458931350510116}\n",
            "{'loss': 2.4697, 'grad_norm': 12.237128257751465, 'learning_rate': 1.003048780487805e-05, 'epoch': 3.481987434434261}\n",
            "{'loss': 2.4419, 'grad_norm': 14.023435592651367, 'learning_rate': 9.878048780487805e-06, 'epoch': 3.5050435183584066}\n",
            "{'loss': 2.4625, 'grad_norm': 9.967162132263184, 'learning_rate': 9.72560975609756e-06, 'epoch': 3.5280996022825524}\n",
            "{'loss': 2.4552, 'grad_norm': 9.740726470947266, 'learning_rate': 9.573170731707317e-06, 'epoch': 3.5511556862066977}\n",
            "{'loss': 2.4468, 'grad_norm': 9.465620040893555, 'learning_rate': 9.420731707317074e-06, 'epoch': 3.574211770130843}\n",
            "{'loss': 2.4497, 'grad_norm': 9.205748558044434, 'learning_rate': 9.26829268292683e-06, 'epoch': 3.597267854054989}\n",
            "{'loss': 2.4587, 'grad_norm': 9.884926795959473, 'learning_rate': 9.115853658536585e-06, 'epoch': 3.6203239379791343}\n",
            "{'loss': 2.4043, 'grad_norm': 9.662129402160645, 'learning_rate': 8.963414634146342e-06, 'epoch': 3.6433800219032797}\n",
            "{'loss': 2.4308, 'grad_norm': 10.007548332214355, 'learning_rate': 8.810975609756097e-06, 'epoch': 3.666436105827425}\n",
            "{'loss': 2.4293, 'grad_norm': 10.888378143310547, 'learning_rate': 8.658536585365854e-06, 'epoch': 3.6894921897515705}\n",
            "{'eval_loss': 2.2994425296783447, 'eval_rouge1': 0.377953901914031, 'eval_rouge2': 0.23684847463864683, 'eval_rougeL': 0.33664871347080916, 'eval_rougeLsum': 0.3373560058316624, 'eval_runtime': 19.0752, 'eval_samples_per_second': 1.048, 'eval_steps_per_second': 0.262, 'epoch': 3.6894921897515705}\n",
            "{'loss': 2.4329, 'grad_norm': 11.634408950805664, 'learning_rate': 8.50609756097561e-06, 'epoch': 3.7125482736757163}\n",
            "{'loss': 2.4227, 'grad_norm': 10.160643577575684, 'learning_rate': 8.353658536585366e-06, 'epoch': 3.7356043575998616}\n",
            "{'loss': 2.4227, 'grad_norm': 10.441740989685059, 'learning_rate': 8.201219512195122e-06, 'epoch': 3.758660441524007}\n",
            "{'loss': 2.4435, 'grad_norm': 11.819329261779785, 'learning_rate': 8.048780487804879e-06, 'epoch': 3.781716525448153}\n",
            "{'loss': 2.4102, 'grad_norm': 11.195652961730957, 'learning_rate': 7.896341463414634e-06, 'epoch': 3.804772609372298}\n",
            "{'loss': 2.4481, 'grad_norm': 10.415328025817871, 'learning_rate': 7.743902439024391e-06, 'epoch': 3.8278286932964436}\n",
            "{'loss': 2.412, 'grad_norm': 10.08780288696289, 'learning_rate': 7.591463414634147e-06, 'epoch': 3.850884777220589}\n",
            "{'loss': 2.4007, 'grad_norm': 8.837145805358887, 'learning_rate': 7.439024390243902e-06, 'epoch': 3.8739408611447343}\n",
            "{'loss': 2.4471, 'grad_norm': 10.929951667785645, 'learning_rate': 7.2865853658536584e-06, 'epoch': 3.89699694506888}\n",
            "{'loss': 2.4398, 'grad_norm': 9.844974517822266, 'learning_rate': 7.1341463414634146e-06, 'epoch': 3.9200530289930255}\n",
            "{'eval_loss': 2.287888288497925, 'eval_rouge1': 0.3848917977162041, 'eval_rouge2': 0.24646707469237605, 'eval_rougeL': 0.3451677963882126, 'eval_rougeLsum': 0.3454799136793344, 'eval_runtime': 18.3855, 'eval_samples_per_second': 1.088, 'eval_steps_per_second': 0.272, 'epoch': 3.9200530289930255}\n",
            "{'loss': 2.4166, 'grad_norm': 11.272649765014648, 'learning_rate': 6.981707317073171e-06, 'epoch': 3.943109112917171}\n",
            "{'loss': 2.4122, 'grad_norm': 11.874253273010254, 'learning_rate': 6.829268292682927e-06, 'epoch': 3.9661651968413167}\n",
            "{'loss': 2.4452, 'grad_norm': 10.70010757446289, 'learning_rate': 6.676829268292683e-06, 'epoch': 3.989221280765462}\n",
            "{'loss': 2.4246, 'grad_norm': 10.758524894714355, 'learning_rate': 6.524390243902439e-06, 'epoch': 4.012450285319039}\n",
            "{'loss': 2.417, 'grad_norm': 11.2822265625, 'learning_rate': 6.371951219512195e-06, 'epoch': 4.035506369243184}\n",
            "{'loss': 2.4147, 'grad_norm': 9.360004425048828, 'learning_rate': 6.219512195121951e-06, 'epoch': 4.05856245316733}\n",
            "{'loss': 2.4111, 'grad_norm': 11.416108131408691, 'learning_rate': 6.0670731707317075e-06, 'epoch': 4.081618537091475}\n",
            "{'loss': 2.382, 'grad_norm': 11.492987632751465, 'learning_rate': 5.914634146341464e-06, 'epoch': 4.10467462101562}\n",
            "{'loss': 2.4282, 'grad_norm': 9.39499568939209, 'learning_rate': 5.76219512195122e-06, 'epoch': 4.127730704939766}\n",
            "{'loss': 2.4591, 'grad_norm': 11.820181846618652, 'learning_rate': 5.609756097560976e-06, 'epoch': 4.150786788863911}\n",
            "{'eval_loss': 2.279902696609497, 'eval_rouge1': 0.37831667522525936, 'eval_rouge2': 0.23872561084526855, 'eval_rougeL': 0.33878716809435383, 'eval_rougeLsum': 0.33887650192618574, 'eval_runtime': 18.9271, 'eval_samples_per_second': 1.057, 'eval_steps_per_second': 0.264, 'epoch': 4.150786788863911}\n",
            "{'loss': 2.4303, 'grad_norm': 9.737497329711914, 'learning_rate': 5.457317073170732e-06, 'epoch': 4.1738428727880565}\n",
            "{'loss': 2.3994, 'grad_norm': 9.733914375305176, 'learning_rate': 5.304878048780487e-06, 'epoch': 4.196898956712203}\n",
            "{'loss': 2.3995, 'grad_norm': 10.40052318572998, 'learning_rate': 5.152439024390244e-06, 'epoch': 4.219955040636348}\n",
            "{'loss': 2.395, 'grad_norm': 9.013148307800293, 'learning_rate': 4.9999999999999996e-06, 'epoch': 4.243011124560494}\n",
            "{'loss': 2.3975, 'grad_norm': 11.799115180969238, 'learning_rate': 4.8475609756097565e-06, 'epoch': 4.266067208484639}\n",
            "{'loss': 2.4414, 'grad_norm': 9.795778274536133, 'learning_rate': 4.695121951219512e-06, 'epoch': 4.289123292408784}\n",
            "{'loss': 2.4133, 'grad_norm': 9.973028182983398, 'learning_rate': 4.542682926829269e-06, 'epoch': 4.31217937633293}\n",
            "{'loss': 2.4078, 'grad_norm': 11.599930763244629, 'learning_rate': 4.390243902439024e-06, 'epoch': 4.335235460257075}\n",
            "{'loss': 2.4304, 'grad_norm': 9.418218612670898, 'learning_rate': 4.237804878048781e-06, 'epoch': 4.3582915441812204}\n",
            "{'loss': 2.4195, 'grad_norm': 9.966973304748535, 'learning_rate': 4.085365853658536e-06, 'epoch': 4.381347628105367}\n",
            "{'eval_loss': 2.2772135734558105, 'eval_rouge1': 0.38521104054340516, 'eval_rouge2': 0.24675068563270325, 'eval_rougeL': 0.3406360353128802, 'eval_rougeLsum': 0.34129019729203425, 'eval_runtime': 18.4795, 'eval_samples_per_second': 1.082, 'eval_steps_per_second': 0.271, 'epoch': 4.381347628105367}\n",
            "{'loss': 2.4128, 'grad_norm': 11.779458999633789, 'learning_rate': 3.932926829268293e-06, 'epoch': 4.404403712029512}\n",
            "{'loss': 2.3996, 'grad_norm': 10.371357917785645, 'learning_rate': 3.7804878048780486e-06, 'epoch': 4.4274597959536575}\n",
            "{'loss': 2.4129, 'grad_norm': 8.527364730834961, 'learning_rate': 3.628048780487805e-06, 'epoch': 4.450515879877803}\n",
            "{'loss': 2.4197, 'grad_norm': 10.543158531188965, 'learning_rate': 3.4756097560975613e-06, 'epoch': 4.473571963801948}\n",
            "{'loss': 2.4183, 'grad_norm': 9.811819076538086, 'learning_rate': 3.3231707317073174e-06, 'epoch': 4.496628047726094}\n",
            "{'loss': 2.3847, 'grad_norm': 8.850773811340332, 'learning_rate': 3.1707317073170736e-06, 'epoch': 4.519684131650239}\n",
            "{'loss': 2.4466, 'grad_norm': 9.19994068145752, 'learning_rate': 3.0182926829268297e-06, 'epoch': 4.542740215574384}\n",
            "{'loss': 2.4339, 'grad_norm': 10.871662139892578, 'learning_rate': 2.865853658536586e-06, 'epoch': 4.56579629949853}\n",
            "{'loss': 2.4027, 'grad_norm': 10.699763298034668, 'learning_rate': 2.7134146341463415e-06, 'epoch': 4.588852383422676}\n",
            "{'loss': 2.4256, 'grad_norm': 10.620777130126953, 'learning_rate': 2.5609756097560977e-06, 'epoch': 4.611908467346821}\n",
            "{'eval_loss': 2.2776732444763184, 'eval_rouge1': 0.3806373969898417, 'eval_rouge2': 0.23938542202969126, 'eval_rougeL': 0.33497131378493006, 'eval_rougeLsum': 0.33555611861295, 'eval_runtime': 18.9983, 'eval_samples_per_second': 1.053, 'eval_steps_per_second': 0.263, 'epoch': 4.611908467346821}\n",
            "{'loss': 2.4197, 'grad_norm': 8.680694580078125, 'learning_rate': 2.408536585365854e-06, 'epoch': 4.634964551270967}\n",
            "{'loss': 2.4375, 'grad_norm': 10.314810752868652, 'learning_rate': 2.25609756097561e-06, 'epoch': 4.658020635195112}\n",
            "{'loss': 2.3788, 'grad_norm': 10.446786880493164, 'learning_rate': 2.103658536585366e-06, 'epoch': 4.6810767191192575}\n",
            "{'loss': 2.405, 'grad_norm': 9.397456169128418, 'learning_rate': 1.951219512195122e-06, 'epoch': 4.704132803043403}\n",
            "{'loss': 2.4061, 'grad_norm': 9.964266777038574, 'learning_rate': 1.7987804878048781e-06, 'epoch': 4.727188886967548}\n",
            "{'loss': 2.4322, 'grad_norm': 10.585006713867188, 'learning_rate': 1.6463414634146342e-06, 'epoch': 4.7502449708916945}\n",
            "{'loss': 2.3887, 'grad_norm': 11.28364372253418, 'learning_rate': 1.4939024390243904e-06, 'epoch': 4.77330105481584}\n",
            "{'loss': 2.3988, 'grad_norm': 9.288885116577148, 'learning_rate': 1.3414634146341463e-06, 'epoch': 4.796357138739985}\n",
            "{'loss': 2.3826, 'grad_norm': 10.446377754211426, 'learning_rate': 1.1890243902439024e-06, 'epoch': 4.819413222664131}\n",
            "{'loss': 2.4338, 'grad_norm': 9.383787155151367, 'learning_rate': 1.0365853658536586e-06, 'epoch': 4.842469306588276}\n",
            "{'eval_loss': 2.277078151702881, 'eval_rouge1': 0.3826433934544623, 'eval_rouge2': 0.24462022641671638, 'eval_rougeL': 0.3422076639299248, 'eval_rougeLsum': 0.3428772780911252, 'eval_runtime': 18.7731, 'eval_samples_per_second': 1.065, 'eval_steps_per_second': 0.266, 'epoch': 4.842469306588276}\n",
            "{'loss': 2.4046, 'grad_norm': 10.746038436889648, 'learning_rate': 8.841463414634147e-07, 'epoch': 4.865525390512421}\n",
            "{'loss': 2.4104, 'grad_norm': 10.132163047790527, 'learning_rate': 7.317073170731708e-07, 'epoch': 4.888581474436567}\n",
            "{'loss': 2.3793, 'grad_norm': 9.099323272705078, 'learning_rate': 5.792682926829268e-07, 'epoch': 4.911637558360712}\n",
            "{'loss': 2.4238, 'grad_norm': 9.668848991394043, 'learning_rate': 4.2682926829268293e-07, 'epoch': 4.9346936422848575}\n",
            "{'loss': 2.4165, 'grad_norm': 10.850341796875, 'learning_rate': 2.74390243902439e-07, 'epoch': 4.957749726209004}\n",
            "{'loss': 2.3968, 'grad_norm': 9.030694961547852, 'learning_rate': 1.2195121951219514e-07, 'epoch': 4.980805810133149}\n",
            "{'train_runtime': 43452.6706, 'train_samples_per_second': 15.97, 'train_steps_per_second': 0.249, 'train_loss': 3.2928555238730794, 'epoch': 4.999250677272466}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=10840, training_loss=3.2928555238730794, metrics={'train_runtime': 43452.6706, 'train_samples_per_second': 15.97, 'train_steps_per_second': 0.249, 'train_loss': 3.2928555238730794, 'epoch': 4.999250677272466})"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "from transformers import Seq2SeqTrainer\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=metrics_func,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"].select(range(20)),\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Eğitilen modeli kaydet\n",
        "output_dir = \"./trained_model\"  # Kaydedilecek dizin\n",
        "trainer.save_model(output_dir)  # Modeli ve tokenizer'ı kaydeder\n",
        "\n",
        "# Tokenizer'ı ayrıca kaydetmek isterseniz\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model ve tokenizer {output_dir} dizinine kaydedildi.\")"
      ],
      "metadata": {
        "id": "1yY9QcafhjpV",
        "outputId": "0d16c119-ac67-4426-c922-5944b250c319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ve tokenizer ./trained_model dizinine kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Eğitilen modeli ve tokenizer'ı yükle\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"./trained_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./trained_model\")\n"
      ],
      "metadata": {
        "id": "piGBJOV-ibHw",
        "outputId": "78a003bf-4297-4542-a8ad-94bdf7310fbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"Dünyamızda 1900’lü yıllardan günümüze kadar dil öğretiminde çeşitli metinler kullanılmıştır. Bunlar “ edebi metinler, üretilmiş metinler, özgün ve özel metinler ” başlıkları altında toplanmıştır. Metinlerin seçimi dil öğretim yaklaşım ve yöntemlerine göre değişmektedir. Her yaklaşım kendine özgü metin kullanmıştır. Geleneksel yaklaşımda dil bilgisi kuralları, atasözleri, edebiyat, genel kültür gibi konuların öğretimine ağırlık verildiğinden edebi metinler kullanılmıştır. Davranışçı yaklaşımda dil davranış olarak ele alınmış, tekrar, taklit ve ezberleme yoluyla öğretilmiştir. Bu yaklaşımda edebi metinler yerine üretilmiş metinler kullanılmıştır. Bilişsel yaklaşımda “dil iletişim aracıdır” görüşü yayılmış ve özgün metinler kullanılmaya başlanmıştır. \"\n"
      ],
      "metadata": {
        "id": "VKEEh23hislk"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(\n",
        "    test_text,\n",
        "    return_tensors=\"pt\",  # PyTorch tensörleri olarak döner\n",
        "    max_length=1024,      # Modelin giriş sınırı\n",
        "    truncation=True       # Çok uzun metinleri keser\n",
        ")\n"
      ],
      "metadata": {
        "id": "P0vpkXDdimu6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Özetleme\n",
        "output_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    attention_mask=inputs[\"attention_mask\"],\n",
        "    max_length=128,  # Özet uzunluğu sınırı\n",
        "    num_beams=4,     # Beam search kullanımı\n",
        "    no_repeat_ngram_size=2,  # Tekrar eden n-gramları engeller\n",
        "    length_penalty=0.6       # Kısa özetlere öncelik\n",
        ")\n",
        "\n",
        "# Özet çözümleme\n",
        "summary = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "print(\"Özet:\", summary)\n"
      ],
      "metadata": {
        "id": "RNB0YFddixHG",
        "outputId": "d2c728ba-c948-426d-f700-0e80b3b76898",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Özet: Dünyamızda 1900’lü yıllardan günümüze kadar dil öğretiminde çeşitli metinler kullanılmıştır.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aSDoLGHwj3E9",
        "outputId": "fc0111cb-b972-4a68-900f-49bb63ac221b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}